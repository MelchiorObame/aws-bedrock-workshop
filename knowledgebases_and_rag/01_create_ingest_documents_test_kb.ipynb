{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Bases for Amazon Bedrock - Comparing Vector Store Options\n",
    "\n",
    "This notebook demonstrates creating Amazon Bedrock Knowledge Bases with two different vector store backends:\n",
    "1. **Amazon OpenSearch Serverless (AOSS)** - Managed vector search with millisecond latency\n",
    "2. **Amazon S3 Vectors** - Cost-effective vector storage with sub-second latency (Preview)\n",
    "\n",
    "Both Knowledge Bases will use the same data source (Amazon S3 bucket with shareholder letters), allowing you to compare their performance and characteristics in the next notebook.\n",
    "\n",
    "#### Notebook Walkthrough\n",
    "\n",
    "We will create two parallel data pipelines that ingest the same documents into two different Knowledge Bases:\n",
    "\n",
    "**AOSS Knowledge Base:**\n",
    "- Traditional vector database approach\n",
    "- Millisecond query latency\n",
    "- Higher cost for large datasets\n",
    "- Mature, production-ready\n",
    "\n",
    "**S3 Vectors Knowledge Base:**\n",
    "- Native S3 vector storage (Preview)\n",
    "- Sub-second query latency\n",
    "- Cost-effective for large datasets\n",
    "- Seamless S3 integration\n",
    "\n",
    "![data_ingestion.png](./images/data_ingestion.png)\n",
    "\n",
    "### High-Level Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     Amazon S3 Data Source                        â”‚\n",
    "â”‚                  (Shareholder Letters PDFs)                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         â”‚\n",
    "                         â”‚ Same documents ingested into both KBs\n",
    "                         â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚                               â”‚\n",
    "         â–¼                               â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   AOSS Knowledge    â”‚         â”‚ S3 Vectors Knowledgeâ”‚\n",
    "â”‚       Base          â”‚         â”‚       Base          â”‚\n",
    "â”‚                     â”‚         â”‚                     â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚ Titan Embed   â”‚  â”‚         â”‚  â”‚ Titan Embed   â”‚  â”‚\n",
    "â”‚  â”‚  Text v2      â”‚  â”‚         â”‚  â”‚  Text v2      â”‚  â”‚\n",
    "â”‚  â”‚ (1024 dim)    â”‚  â”‚         â”‚  â”‚ (1024 dim)    â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚          â”‚          â”‚         â”‚          â”‚          â”‚\n",
    "â”‚          â–¼          â”‚         â”‚          â–¼          â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚  OpenSearch   â”‚  â”‚         â”‚  â”‚  S3 Vectors   â”‚  â”‚\n",
    "â”‚  â”‚  Serverless   â”‚  â”‚         â”‚  â”‚    Index      â”‚  â”‚\n",
    "â”‚  â”‚  Collection   â”‚  â”‚         â”‚  â”‚               â”‚  â”‚\n",
    "â”‚  â”‚               â”‚  â”‚         â”‚  â”‚  - Cosine     â”‚  â”‚\n",
    "â”‚  â”‚  - HNSW       â”‚  â”‚         â”‚  â”‚  - Float32    â”‚  â”‚\n",
    "â”‚  â”‚  - FAISS      â”‚  â”‚         â”‚  â”‚  - 1024 dim   â”‚  â”‚\n",
    "â”‚  â”‚  - L2 distanceâ”‚  â”‚         â”‚  â”‚               â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚                               â”‚\n",
    "         â”‚                               â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         â”‚\n",
    "                         â–¼\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚  Bedrock Agent      â”‚\n",
    "              â”‚  Runtime API        â”‚\n",
    "              â”‚                     â”‚\n",
    "              â”‚  - Retrieve         â”‚\n",
    "              â”‚  - RetrieveAndGen   â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         â”‚\n",
    "                         â–¼\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚   Nova/Claude/etc   â”‚\n",
    "              â”‚   (Generation)      â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "#### Steps: \n",
    "1. Create IAM execution roles with policies for both vector stores\n",
    "2. Create Amazon OpenSearch Serverless collection and index\n",
    "3. Create S3 Vectors bucket and index\n",
    "4. Download sample documents (Amazon shareholder letters)\n",
    "5. Create S3 bucket as data source and upload documents\n",
    "6. Create two Knowledge Bases (one for each vector store)\n",
    "7. Create data sources connecting both KBs to the same S3 bucket\n",
    "8. Start ingestion jobs for both Knowledge Bases\n",
    "\n",
    "Once both Knowledge Bases are ready, you can compare their performance in:\n",
    "- [02_managed-rag-kb-retrieve-generate-api.ipynb](02_managed-rag-kb-retrieve-generate-api.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and shared configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import pprint\n",
    "from utility import create_bedrock_execution_role, create_aoss_policy_attach_bedrock_execution_role, create_policies_in_aoss, interactive_sleep_for\n",
    "import random\n",
    "from retrying import retry\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from util.tagging import standard_tags, standard_tags_kv, standard_tags_kv_lc\n",
    "from util.model_selector import create_text_model_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = os.environ.get(\"AWS_REGION\", \"us-east-1\")\n",
    "#Clients\n",
    "bedrock_agent_client = boto3.client(service_name=\"bedrock-agent\", region_name=region_name)\n",
    "sts_client = boto3.client(service_name=\"sts\", region_name=region_name)\n",
    "s3_client = boto3.client(service_name=\"s3\", region_name=region_name)\n",
    "aoss_client = boto3.client(service_name=\"opensearchserverless\", region_name=region_name)\n",
    "s3vectors_client = boto3.client('s3vectors', region_name=region_name)\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "#Extra params\n",
    "suffix = random.randrange(200, 900)\n",
    "timestamp = str(int(time.time()))\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "#Buckets and vector store names\n",
    "s3_suffix = f\"{region_name}-{account_id}\"\n",
    "source_bucket_name = f'bedrock-kb-{s3_suffix}-{suffix}'\n",
    "vector_store_name_aoss = f'bedrock-sample-rag-aoss-{suffix}'\n",
    "index_name_aoss = f\"bedrock-sample-rag-index-aoss-{suffix}\"\n",
    "vector_bucket_name = f\"bedrock-kb-s3vectors-{suffix}-{timestamp}\"\n",
    "vector_index_name = f\"bedrock-kb-index-{suffix}\"\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "#Knowledge base config for aoss\n",
    "aoss_kb_name = f\"bedrock-sample-knowledge-base-aoss-{suffix}\"\n",
    "aoss_kb_description = \"Amazon shareholder letter Knowledge Base backed by AOSS.\"\n",
    "\n",
    "\n",
    "# Knowledge Base configuration for S3 Vectors\n",
    "s3vectors_kb_name = f\"bedrock-s3vectors-knowledge-base-{suffix}\"\n",
    "s3vectors_kb_description = \"Amazon shareholder letter Knowledge Base with S3 Vectors storage.\"\n",
    "\n",
    "\n",
    "# Ingest strategy - How to ingest data from the data source\n",
    "chunkingStrategyConfiguration = {\n",
    "    \"chunkingStrategy\": \"FIXED_SIZE\",\n",
    "    \"fixedSizeChunkingConfiguration\": {\n",
    "        \"maxTokens\": 512,\n",
    "        \"overlapPercentage\": 20\n",
    "    }\n",
    "}\n",
    "\n",
    "# The data source to ingest documents from, into the OpenSearch serverless and S3 Vector Knowledge Base index\n",
    "s3Configuration = {\n",
    "    \"bucketArn\": f\"arn:aws:s3:::{source_bucket_name}\",\n",
    "    # \"inclusionPrefixes\":[\"*.*\"] # you can use this if you want to create a Knowledge Base using data within S3 prefixes.\n",
    "}\n",
    "\n",
    "# The embedding model used by Bedrock to embed ingested documents, and realtime prompts\n",
    "embeddingModelArn = f\"arn:aws:bedrock:{region_name}::foundation-model/amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "#Must match the embedding dimension of the selected embedding model\n",
    "s3_vector_dimension = 1024  # Titan Embed Text v2 dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create S3 bucket data source for Knowledge Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if bucket exists, and if not create S3 bucket for Knowledge Base data source\n",
    "try:\n",
    "    s3_client.head_bucket(Bucket=source_bucket_name)\n",
    "    print(f'Bucket {source_bucket_name} Exists')\n",
    "except ClientError as e:\n",
    "    print(f'Creating bucket {source_bucket_name}')\n",
    "    if region_name == \"us-east-1\":\n",
    "        s3bucket = s3_client.create_bucket(\n",
    "            Bucket=source_bucket_name\n",
    "        )\n",
    "    else:\n",
    "        s3bucket = s3_client.create_bucket(\n",
    "        Bucket=source_bucket_name,\n",
    "        CreateBucketConfiguration={'LocationConstraint': region_name }\n",
    "    )\n",
    "    s3_client.put_bucket_tagging(\n",
    "        Bucket=source_bucket_name,\n",
    "        Tagging={\n",
    "            'TagSet': standard_tags_kv\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store source_bucket_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data to ingest into our S3 Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and prepare dataset\n",
    "!mkdir -p ./data\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "data_root = \"./data/\"\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root + filenames[idx]\n",
    "    urlretrieve(url, file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to S3 Bucket data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to s3 to the bucket that was configured as a data source to the Knowledge Base\n",
    "def uploadDirectory(path,bucket_name):\n",
    "        for root,dirs,files in os.walk(path):\n",
    "            for file in files:\n",
    "                s3_client.upload_file(os.path.join(root,file),bucket_name,file)\n",
    "\n",
    "uploadDirectory(data_root, source_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vector store - Amazon OpenSearch Serverless (AOSS) index\n",
    "\n",
    "### Step 1 - Create AOSS policies and collection\n",
    "First of all we have to create a vector store. In this section we will use *Amazon OpenSearch Serverless.*\n",
    "\n",
    "Amazon OpenSearch Serverless is a serverless option in Amazon OpenSearch Service. As a developer, you can use OpenSearch Serverless to run petabyte-scale workloads without configuring, managing, and scaling OpenSearch clusters. You get the same interactive millisecond response times as OpenSearch Service with the simplicity of a serverless environment. Pay only for what you use by automatically scaling resources to provide the right amount of capacity for your applicationâ€”without impacting data ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_kb_execution_role_aoss = create_bedrock_execution_role(bucket_name=source_bucket_name)\n",
    "bedrock_kb_execution_role_arn_aoss = bedrock_kb_execution_role_aoss['Role']['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Amazon OpenSeach Serverless collection for the vector store. Note that creation of the collection can take several minutes. You can use the Amazon OpenSearch Serverless console to monitor creation progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create security, network and data access policies within AOSS\n",
    "encryption_policy, network_policy, access_policy = create_policies_in_aoss(\n",
    "    vector_store_name=vector_store_name_aoss,\n",
    "    aoss_client=aoss_client,\n",
    "    bedrock_kb_execution_role_arn=bedrock_kb_execution_role_arn_aoss)\n",
    "collection = aoss_client.create_collection(name=vector_store_name_aoss,type='VECTORSEARCH', tags=standard_tags_kv_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store encryption_policy network_policy access_policy collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the OpenSearch serverless collection URL\n",
    "collection_id = collection['createCollectionDetail']['id']\n",
    "host = collection_id + '.' + region_name + '.aoss.amazonaws.com'\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for collection creation\n",
    "# This can take couple of minutes to finish\n",
    "def collection_created():    \n",
    "    response = aoss_client.batch_get_collection(names=[vector_store_name_aoss])\n",
    "    return response['collectionDetails'][0]['status'] != 'CREATING'\n",
    "\n",
    "interactive_sleep_for(collection_created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create opensearch serverless access policy and attach it to Bedrock execution role\n",
    "try:\n",
    "    create_aoss_policy_attach_bedrock_execution_role(collection_id=collection_id,\n",
    "                                                    bedrock_kb_execution_role=bedrock_kb_execution_role_aoss)\n",
    "except Exception as e:\n",
    "    print(\"Policy already exists\")\n",
    "    pp.pprint(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth, AuthorizationException, RequestError, AuthenticationException\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWSV4SignerAuth(credentials, region_name, 'aoss')\n",
    "\n",
    "# Build the OpenSearch client\n",
    "oss_api_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Create vector index\n",
    "\n",
    "We will create the vector index in Amazon Opensearch Serverless, with the `knn_vector` type, specifying the dimension size, name, and engine.\n",
    "Read the [OpenSearch documentation on k-NN vector](https://docs.opensearch.org/latest/field-types/supported-field-types/knn-vector/) for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_json = {\n",
    "   \"settings\": {\n",
    "      \"index.knn\": \"true\",\n",
    "       \"number_of_shards\": 1,\n",
    "       \"knn.algo_param.ef_search\": 512,\n",
    "       \"number_of_replicas\": 0,\n",
    "   },\n",
    "   \"mappings\": {\n",
    "      \"properties\": {\n",
    "         \"vector\": {\n",
    "            \"type\": \"knn_vector\",\n",
    "            \"dimension\": 1024,\n",
    "             \"method\": {\n",
    "                 \"name\": \"hnsw\",\n",
    "                 \"engine\": \"faiss\",\n",
    "                 \"space_type\": \"l2\"\n",
    "             },\n",
    "         },\n",
    "         \"text\": {\n",
    "            \"type\": \"text\"\n",
    "         },\n",
    "         \"text-metadata\": {\n",
    "            \"type\": \"text\"\n",
    "         }\n",
    "      }\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to retry as it can take a minute to propagate the security policies to AOSS\n",
    "@retry(retry_on_exception=lambda e: isinstance(e, (AuthenticationException, AuthorizationException)),\n",
    "       wait_fixed=5000,\n",
    "       stop_max_delay=60*1000)\n",
    "def create_index():\n",
    "    # Create index\n",
    "    try:\n",
    "        response = oss_api_client.indices.create(index=index_name_aoss, body=json.dumps(body_json))\n",
    "        print('\\nCreating index:')\n",
    "        pp.pprint(response)\n",
    "    except RequestError as e:\n",
    "        if e.error == 'resource_already_exists_exception':\n",
    "            # oss_api_client.indices.delete(index=index_name_aoss)\n",
    "            print(\"Index already exists. You can delete the index if its already exists by the delete line in this cell.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "create_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Knowledge Base\n",
    "Steps:\n",
    "- Initialize Open search serverless configuration which will include collection ARN, index name, vector field, text field and metadata field.\n",
    "- Initialize chunking strategy, based on which Knowledge Base will split the documents into pieces of size equal to the chunk size mentioned in the `chunkingStrategyConfiguration`.\n",
    "- Initialize the s3 configuration, which will be used to create the data source object later.\n",
    "- Initialize the Titan Embed Text model ARN, as this will be used to create the embeddings for each of the text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearchServerlessConfiguration = {\n",
    "            \"collectionArn\": collection[\"createCollectionDetail\"]['arn'],\n",
    "            \"vectorIndexName\": index_name_aoss,\n",
    "            \"fieldMapping\": {\n",
    "                \"vectorField\": \"vector\",\n",
    "                \"textField\": \"text\",\n",
    "                \"metadataField\": \"text-metadata\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the above configurations as input to the `create_knowledge_base` method, which will create the Knowledge Base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KnowledgeBase\n",
    "from retrying import retry\n",
    "\n",
    "@retry(wait_random_min=1000, wait_random_max=2000,stop_max_attempt_number=7)\n",
    "def create_knowledge_base_aoss_func():\n",
    "    create_kb_response = bedrock_agent_client.create_knowledge_base(\n",
    "        name = aoss_kb_name,\n",
    "        description = aoss_kb_description,\n",
    "        roleArn = bedrock_kb_execution_role_arn_aoss,\n",
    "        knowledgeBaseConfiguration = {\n",
    "            \"type\": \"VECTOR\",\n",
    "            \"vectorKnowledgeBaseConfiguration\": {\n",
    "                \"embeddingModelArn\": embeddingModelArn\n",
    "            }\n",
    "        },\n",
    "        storageConfiguration = {\n",
    "            \"type\": \"OPENSEARCH_SERVERLESS\",\n",
    "            \"opensearchServerlessConfiguration\":opensearchServerlessConfiguration\n",
    "        },\n",
    "        tags=standard_tags\n",
    "    )\n",
    "    return create_kb_response[\"knowledgeBase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    kb_aoss = create_knowledge_base_aoss_func()\n",
    "except Exception as err:\n",
    "    print(f\"{err=}, {type(err)=}\")\n",
    "\n",
    "pp.pprint(kb_aoss)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get KnowledgeBase \n",
    "get_kb_response_aoss = bedrock_agent_client.get_knowledge_base(knowledgeBaseId = kb_aoss['knowledgeBaseId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create S3 Vectors Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Create S3 Vectors bucket and index\n",
    "\n",
    "Amazon S3 Vectors (Preview) provides cost-effective vector storage integrated directly with S3. It offers:\n",
    "- **Cost savings** for large vector datasets\n",
    "- **Sub-second query latency** for retrieval operations  \n",
    "- **Seamless S3 integration** with familiar AWS services\n",
    "- **Automatic scaling** without infrastructure management\n",
    "\n",
    "Let's create an S3 Vectors bucket and index for our second Knowledge Base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"S3 Vectors Configuration:\")\n",
    "print(f\"  Bucket: {vector_bucket_name}\")\n",
    "print(f\"  Index: {vector_index_name}\")\n",
    "print(f\"  Dimension: {s3_vector_dimension}\")\n",
    "\n",
    "# Create S3 Vectors bucket\n",
    "s3vectors_client.create_vector_bucket(\n",
    "    vectorBucketName=vector_bucket_name,\n",
    "    encryptionConfiguration={'sseType': 'AES256'},\n",
    ")\n",
    "print(f\"âœ… Created S3 Vectors bucket: {vector_bucket_name}\")\n",
    "\n",
    "# Create vector index with cosine distance metric\n",
    "s3vectors_client.create_index(\n",
    "    vectorBucketName=vector_bucket_name,\n",
    "    indexName=vector_index_name,\n",
    "    dataType=\"float32\",\n",
    "    dimension=s3_vector_dimension,\n",
    "    distanceMetric=\"cosine\",\n",
    "    metadataConfiguration={\n",
    "            \"nonFilterableMetadataKeys\": [\n",
    "                \"AMAZON_BEDROCK_TEXT\"\n",
    "            ]\n",
    "        }\n",
    ")\n",
    "print(f\"âœ… Created vector index: {vector_index_name}\")\n",
    "\n",
    "# Get the index ARN for Knowledge Base configuration\n",
    "vector_index_arn = f\"arn:aws:s3vectors:{region_name}:{account_id}:bucket/{vector_bucket_name}/index/{vector_index_name}\"\n",
    "print(f\"Vector Index ARN: {vector_index_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create IAM execution role for S3 Vectors Knowledge Base\n",
    "\n",
    "The execution role needs additional permissions for S3 Vectors operations compared to AOSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IAM policy for S3 Vectors access\n",
    "s3vectors_policy_name = f'AmazonBedrockS3VectorsPolicyForKnowledgeBase_{suffix}'\n",
    "\n",
    "s3vectors_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"BedrockInvokeModelPermission\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\"bedrock:InvokeModel\"],\n",
    "            \"Resource\": [embeddingModelArn]\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"S3ListBucketPermission\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\"s3:ListBucket\"],\n",
    "            \"Resource\": [f\"arn:aws:s3:::{source_bucket_name}\"],\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:ResourceAccount\": [account_id]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"S3GetObjectPermission\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\"s3:GetObject\"],\n",
    "            \"Resource\": [f\"arn:aws:s3:::{source_bucket_name}/*\"],\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:ResourceAccount\": [account_id]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"S3VectorsAccessPermission\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3vectors:GetIndex\",\n",
    "                \"s3vectors:QueryVectors\",\n",
    "                \"s3vectors:PutVectors\",\n",
    "                \"s3vectors:GetVectors\",\n",
    "                \"s3vectors:DeleteVectors\"\n",
    "            ],\n",
    "            \"Resource\": vector_index_arn,\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:ResourceAccount\": account_id\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the policy\n",
    "s3vectors_policy = iam_client.create_policy(\n",
    "    PolicyName=s3vectors_policy_name,\n",
    "    PolicyDocument=json.dumps(s3vectors_policy_document),\n",
    "    Description='Policy for S3 Vectors access from Bedrock Knowledge Base',\n",
    "    Tags=standard_tags_kv\n",
    ")\n",
    "\n",
    "s3vectors_policy_arn = s3vectors_policy[\"Policy\"][\"Arn\"]\n",
    "print(f\"Created S3 Vectors policy: {s3vectors_policy_arn}\")\n",
    "\n",
    "# Create execution role for S3 Vectors Knowledge Base\n",
    "s3vectors_role_name = f'AmazonBedrockExecutionRoleForS3Vectors_{suffix}'\n",
    "\n",
    "assume_role_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": \"bedrock.amazonaws.com\"},\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3vectors_kb_execution_role = iam_client.create_role(\n",
    "    RoleName=s3vectors_role_name,\n",
    "    AssumeRolePolicyDocument=json.dumps(assume_role_policy),\n",
    "    Description='Amazon Bedrock Knowledge Base Execution Role for S3 Vectors',\n",
    "    MaxSessionDuration=3600,\n",
    "    Tags=standard_tags_kv\n",
    ")\n",
    "\n",
    "s3vectors_kb_execution_role_arn = s3vectors_kb_execution_role['Role']['Arn']\n",
    "\n",
    "# Attach the S3 Vectors policy\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=s3vectors_role_name,\n",
    "    PolicyArn=s3vectors_policy_arn\n",
    ")\n",
    "\n",
    "print(f\"Created S3 Vectors execution role: {s3vectors_kb_execution_role_arn}\")\n",
    "\n",
    "# Wait for role to propagate\n",
    "print(\"Waiting for IAM role to propagate...\")\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Create S3 Vectors Knowledge Base\n",
    "\n",
    "Now we'll create the second Knowledge Base using S3 Vectors as the storage backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 Vectors storage configuration\n",
    "s3VectorsConfiguration = {\n",
    "    \"indexArn\": vector_index_arn\n",
    "}\n",
    "\n",
    "print(f\"Creating S3 Vectors Knowledge Base: {s3vectors_kb_name}\")\n",
    "\n",
    "# Create S3 Vectors Knowledge Base\n",
    "@retry(wait_random_min=1000, wait_random_max=2000, stop_max_attempt_number=7)\n",
    "def create_s3vectors_knowledge_base():\n",
    "    create_kb_response = bedrock_agent_client.create_knowledge_base(\n",
    "        name=s3vectors_kb_name,\n",
    "        description=s3vectors_kb_description,\n",
    "        roleArn=s3vectors_kb_execution_role_arn,\n",
    "        knowledgeBaseConfiguration={\n",
    "            \"type\": \"VECTOR\",\n",
    "            \"vectorKnowledgeBaseConfiguration\": {\n",
    "                \"embeddingModelArn\": embeddingModelArn,\n",
    "                \"embeddingModelConfiguration\": {\n",
    "                    \"bedrockEmbeddingModelConfiguration\": {\n",
    "                        \"dimensions\": s3_vector_dimension,\n",
    "                        \"embeddingDataType\": \"FLOAT32\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        storageConfiguration={\n",
    "            \"type\": \"S3_VECTORS\",\n",
    "            \"s3VectorsConfiguration\": s3VectorsConfiguration\n",
    "        },\n",
    "        tags=standard_tags\n",
    "    )\n",
    "    return create_kb_response[\"knowledgeBase\"]\n",
    "\n",
    "try:\n",
    "    s3vectors_kb = create_s3vectors_knowledge_base()\n",
    "    pp.pprint(s3vectors_kb)\n",
    "except Exception as err:\n",
    "    print(f\"Error creating S3 Vectors Knowledge Base: {err=}, {type(err)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data sources for Knowledge Bases and start sync jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Create data sources for both Knowledge Bases\n",
    "\n",
    "Now we'll create data sources for both Knowledge Bases, connecting them to the same S3 bucket with our documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataSource for AOSS Knowledge Base \n",
    "create_ds_response = bedrock_agent_client.create_data_source(\n",
    "    name = aoss_kb_name,\n",
    "    description = aoss_kb_description,\n",
    "    knowledgeBaseId = kb_aoss['knowledgeBaseId'],\n",
    "    dataSourceConfiguration = {\n",
    "        \"type\": \"S3\",\n",
    "        \"s3Configuration\":s3Configuration\n",
    "    },\n",
    "    vectorIngestionConfiguration = {\n",
    "        \"chunkingConfiguration\": chunkingStrategyConfiguration\n",
    "    }\n",
    ")\n",
    "\n",
    "ds_aoss = create_ds_response[\"dataSource\"]\n",
    "pp.pprint(ds_aoss)\n",
    "\n",
    "# Get DataSource \n",
    "bedrock_agent_client.get_data_source(knowledgeBaseId = kb_aoss['knowledgeBaseId'], dataSourceId = ds_aoss[\"dataSourceId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data source for S3 Vectors Knowledge Base\n",
    "create_s3vectors_ds_response = bedrock_agent_client.create_data_source(\n",
    "    name=s3vectors_kb_name,\n",
    "    description=s3vectors_kb_description,\n",
    "    knowledgeBaseId=s3vectors_kb['knowledgeBaseId'],\n",
    "    dataSourceConfiguration={\n",
    "        \"type\": \"S3\",\n",
    "        \"s3Configuration\": s3Configuration\n",
    "    },\n",
    "    vectorIngestionConfiguration={\n",
    "        \"chunkingConfiguration\": chunkingStrategyConfiguration\n",
    "    }\n",
    ")\n",
    "\n",
    "s3vectors_ds = create_s3vectors_ds_response[\"dataSource\"]\n",
    "pp.pprint(s3vectors_ds)\n",
    "\n",
    "# Get DataSource \n",
    "bedrock_agent_client.get_data_source(knowledgeBaseId = s3vectors_kb['knowledgeBaseId'], dataSourceId = s3vectors_ds[\"dataSourceId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Start ingestion jobs for both Knowledge Bases\n",
    "\n",
    "We'll start ingestion jobs for both Knowledge Bases simultaneously. This will process the same documents and create embeddings in both vector stores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start ingestion job\n",
    "Once the Knowledge Base and data source is created, we can start the ingestion job.\n",
    "During the ingestion job, Knowledge Base will fetch the documents in the data source, pre-process it to extract text, chunk it based on the chunking size provided, create embeddings of each chunk and then write it to the vector database, in this case AOSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to retry as it can take a minute so the previous settings are effective\n",
    "@retry(retry_on_exception=lambda e: isinstance(e, (bedrock_agent_client.exceptions.ValidationException, bedrock_agent_client.exceptions.ConflictException)),\n",
    "       wait_fixed=5000,\n",
    "       stop_max_delay=60*1000)\n",
    "def start_job():\n",
    "    return bedrock_agent_client.start_ingestion_job(knowledgeBaseId = kb_aoss['knowledgeBaseId'], dataSourceId = ds_aoss[\"dataSourceId\"])\n",
    "\n",
    "start_job_response = start_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_aoss = start_job_response[\"ingestionJob\"]\n",
    "pp.pprint(job_aoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get job \n",
    "def job_completed():\n",
    "  global job_aoss\n",
    "  get_job_response = bedrock_agent_client.get_ingestion_job(\n",
    "    knowledgeBaseId = kb_aoss['knowledgeBaseId'],\n",
    "    dataSourceId = ds_aoss[\"dataSourceId\"],\n",
    "    ingestionJobId = job_aoss[\"ingestionJobId\"]\n",
    "  )\n",
    "  job_aoss = get_job_response[\"ingestionJob\"]\n",
    "  return job_aoss['status']=='COMPLETE'\n",
    "\n",
    "interactive_sleep_for(job_completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start ingestion job for S3 Vectors Knowledge Base\n",
    "@retry(retry_on_exception=lambda e: isinstance(e, (bedrock_agent_client.exceptions.ValidationException, bedrock_agent_client.exceptions.ConflictException)),\n",
    "       wait_fixed=5000,\n",
    "       stop_max_delay=60*1000)\n",
    "def start_s3vectors_job():\n",
    "    return bedrock_agent_client.start_ingestion_job(\n",
    "        knowledgeBaseId=s3vectors_kb['knowledgeBaseId'],\n",
    "        dataSourceId=s3vectors_ds[\"dataSourceId\"]\n",
    "    )\n",
    "\n",
    "start_s3vectors_job_response = start_s3vectors_job()\n",
    "s3vectors_job = start_s3vectors_job_response[\"ingestionJob\"]\n",
    "\n",
    "print(\"Started S3 Vectors ingestion job:\")\n",
    "pp.pprint(s3vectors_job)\n",
    "\n",
    "# Wait for S3 Vectors ingestion job to complete\n",
    "def s3vectors_job_completed():\n",
    "    global s3vectors_job\n",
    "    get_job_response = bedrock_agent_client.get_ingestion_job(\n",
    "        knowledgeBaseId=s3vectors_kb['knowledgeBaseId'],\n",
    "        dataSourceId=s3vectors_ds[\"dataSourceId\"],\n",
    "        ingestionJobId=s3vectors_job[\"ingestionJobId\"]\n",
    "    )\n",
    "    s3vectors_job = get_job_response[\"ingestionJob\"]\n",
    "    return s3vectors_job['status'] == 'COMPLETE'\n",
    "\n",
    "print(\"Waiting for S3 Vectors ingestion job to complete...\")\n",
    "interactive_sleep_for(s3vectors_job_completed)\n",
    "print(\"âœ… S3 Vectors ingestion complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Knowledge Base Id in bedrock, that corresponds to the Opensearch index in the collection we created before, we will use it for the invocation later\n",
    "kb_id_aoss = kb_aoss[\"knowledgeBaseId\"]\n",
    "kb_id_s3vectors = s3vectors_kb[\"knowledgeBaseId\"]\n",
    "\n",
    "print(f\"\\nğŸ“Š Knowledge Base Summary:\")\n",
    "print(f\"  AOSS KB ID: {kb_id_aoss}\")\n",
    "print(f\"  S3 Vectors KB ID: {kb_id_s3vectors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the kb_id for invocation later in the invoke request\n",
    "%store kb_id_aoss\n",
    "%store kb_id_s3vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Chllenges\n",
    "- Read the [blog post](https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-knowledge-bases-now-supports-metadata-filtering-to-improve-retrieval-accuracy) on metadata filtering\n",
    "- Go to knowledgebases_and_rag/data directory and review the metadata files\n",
    "- Add \"year\" attributte to each of the metadata files\n",
    "- Upload the files to S3, and sync the knowledge base from the AWS console\n",
    "- Test the knowledge base from the knowledge bast test environment in the AWS console, use Filters section with format key = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ… Successfully created two Knowledge Bases:\n",
    "\n",
    "1. **AOSS Knowledge Base** (`kb_id_aoss`)\n",
    "   - Vector Store: Amazon OpenSearch Serverless\n",
    "   - Latency: Milliseconds\n",
    "   - Best for: Production workloads requiring ultra-low latency\n",
    "\n",
    "2. **S3 Vectors Knowledge Base** (`kb_id_s3vectors`)\n",
    "   - Vector Store: Amazon S3 Vectors (Preview)\n",
    "   - Latency: Sub-second\n",
    "   - Best for: Cost-effective large-scale vector storage\n",
    "\n",
    "Both Knowledge Bases:\n",
    "- Use the same embedding model (Titan Embed Text v2)\n",
    "- Have the same chunking strategy (512 tokens, 20% overlap)\n",
    "- Are connected to the same S3 data source\n",
    "- Contain the same Amazon shareholder letters\n",
    "\n",
    "You can now proceed to the next notebook to compare their retrieval performance:\n",
    "- [02_managed-rag-kb-retrieve-generate-api.ipynb](02_managed-rag-kb-retrieve-generate-api.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
