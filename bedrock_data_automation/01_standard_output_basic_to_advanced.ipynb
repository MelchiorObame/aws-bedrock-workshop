{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe82768",
   "metadata": {},
   "source": [
    "# Lab 1: BDA Standard Output - Basic to Advanced\n",
    "\n",
    "Amazon Bedrock Data Automation (BDA) transforms unstructured content like documents, images, video, and audio into structured, actionable data using generative AI. This lab introduces BDA concepts and demonstrates both basic and advanced standard output configurations.\n",
    "\n",
    "BDA offers two primary processing modes:\n",
    "- **Standard output**: Default processing that extracts commonly needed information based on data type\n",
    "- **Custom output**: Targeted extraction using blueprints to define specific fields and formats\n",
    "\n",
    "This lab focuses on standard output, progressing from basic usage to advanced configuration options.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "- Understand BDA's core concepts and workflow\n",
    "- Set up the necessary AWS resources and permissions\n",
    "- Process documents using basic standard output\n",
    "- Create and configure BDA projects with advanced standard output settings\n",
    "- Understand different granularity levels and their use cases\n",
    "- Enable generative fields for enhanced document understanding\n",
    "- Work with bounding boxes for visual element positioning\n",
    "- Export document data in multiple formats\n",
    "- Analyze both simple and complex documents\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Configure IAM Permissions\n",
    "\n",
    "Ensure your execution role includes the following IAM policies:\n",
    "- `AmazonBedrockFullAccess`\n",
    "- `AmazonS3FullAccess`\n",
    "\n",
    "If you are participating in an AWS-hosted event, these IAM policies have already been configured for your account.\n",
    "\n",
    "### Install Required Libraries\n",
    "\n",
    "The dependencies needed for this lab have already been installed when you set up the `venv` environment. \n",
    "\n",
    "If you are running the notebook in your own account, you need to install the following dependencies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f7c8a9",
   "metadata": {},
   "source": [
    "```python\n",
    "%pip install --no-warn-conflicts boto3 itables==2.2.4 PyPDF2==3.0.1 --upgrade -q\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29e7df6",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's configure the environment and initialize the AWS clients we'll need throughout this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ae48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import JSON, Markdown\n",
    "\n",
    "# Get account details\n",
    "current_region = boto3.session.Session().region_name\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "\n",
    "# Initialize BDA clients\n",
    "bda_client = boto3.client('bedrock-data-automation')\n",
    "bda_runtime_client = boto3.client('bedrock-data-automation-runtime')\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Define bucket name\n",
    "bda_bucket = f\"pace-bootcamp-bda-bucket-{account_id}-{current_region}\"\n",
    "\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"Region: {current_region}\")\n",
    "print(f\"S3 bucket: {bda_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5417380b",
   "metadata": {},
   "source": [
    "Create an S3 bucket to use with Amazon BDA and tag it for better resource management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.create_bucket(Bucket=bda_bucket)\n",
    "s3_client.put_bucket_tagging(Bucket=bda_bucket, Tagging={'TagSet':[{'Key':'app','Value':'pace_bootcamp'}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure S3 locations for BDA\n",
    "bda_s3_input_location = f's3://{bda_bucket}/bda/input'\n",
    "bda_s3_output_location = f's3://{bda_bucket}/bda/output'\n",
    "\n",
    "print(f\"BDA input location: {bda_s3_input_location}\")\n",
    "print(f\"BDA output location: {bda_s3_output_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b978152",
   "metadata": {},
   "source": [
    "## Import Helper Functions\n",
    "\n",
    "We'll import utility functions from our shared helper module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper_functions import (\n",
    "    get_bucket_and_key,\n",
    "    read_s3_object,\n",
    "    wait_for_job_to_complete,\n",
    "    wait_for_project_completion,\n",
    "    download_document,\n",
    "    preview_pdf_pages,\n",
    "    restart_kernel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e294dfd5",
   "metadata": {},
   "source": [
    "# Part A: Basic Standard Output\n",
    "\n",
    "## Prepare Sample Document\n",
    "\n",
    "For the first part of this lab, we'll use a sample bank statement image. This document type is commonly processed in financial services for account verification and transaction analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local paths\n",
    "local_download_path = \"data/documents/\"\n",
    "local_file_name = \"BankStatement.jpg\"\n",
    "file_path_local = f\"{local_download_path}/{local_file_name}\"\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(local_download_path, exist_ok=True)\n",
    "\n",
    "# For this lab, we'll use the existing sample file\n",
    "# In a real scenario, you would download or prepare your document here\n",
    "\n",
    "# Upload document to S3\n",
    "document_s3_uri = f'{bda_s3_input_location}/{local_file_name}'\n",
    "target_s3_bucket, target_s3_key = get_bucket_and_key(document_s3_uri)\n",
    "\n",
    "# Upload the file to S3\n",
    "s3_client.upload_file(file_path_local, target_s3_bucket, target_s3_key)\n",
    "\n",
    "print(f\"Local file path: {file_path_local}\")\n",
    "print(f\"S3 URI: {document_s3_uri}\")\n",
    "print(f\"S3 key: {target_s3_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33be957",
   "metadata": {},
   "source": [
    "### View Sample Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the document in the notebook\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=file_path_local, width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e01364",
   "metadata": {},
   "source": [
    "## Understanding BDA Standard Output\n",
    "\n",
    "Standard output provides default structured insights without requiring any configuration. When you send a document to BDA with no additional parameters, it returns:\n",
    "\n",
    "- **Metadata**: Document location, page count, processing details\n",
    "- **Document**: Statistics about elements, tables, figures\n",
    "- **Pages**: Markdown representation of each page\n",
    "- **Elements**: Detailed breakdown of text blocks, figures, tables\n",
    "\n",
    "Let's see this in action.\n",
    "\n",
    "## Invoke BDA for Basic Standard Output\n",
    "\n",
    "The simplest way to use BDA is through the `InvokeDataAutomationAsync` API with minimal configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb54fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Processing document: {document_s3_uri}\")\n",
    "print(f\"Output location: {bda_s3_output_location}\")\n",
    "\n",
    "response = bda_runtime_client.invoke_data_automation_async(\n",
    "    inputConfiguration={        \n",
    "        's3Uri': document_s3_uri\n",
    "    },\n",
    "    outputConfiguration={\n",
    "        's3Uri': bda_s3_output_location\n",
    "    },\n",
    "    dataAutomationProfileArn=f'arn:aws:bedrock:{current_region}:{account_id}:data-automation-profile/us.data-automation-v1',\n",
    "    dataAutomationConfiguration={\n",
    "        'dataAutomationProjectArn': f'arn:aws:bedrock:{current_region}:aws:data-automation-project/public-default',\n",
    "    }\n",
    ")\n",
    "\n",
    "invocation_arn = response[\"invocationArn\"]\n",
    "print(f\"Job submitted with invocation ARN: {invocation_arn}\")\n",
    "\n",
    "JSON(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d238a",
   "metadata": {},
   "source": [
    "## Monitor Job Status\n",
    "\n",
    "BDA processes documents asynchronously. Let's monitor the job progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1704a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_response = wait_for_job_to_complete(invocation_arn=invocation_arn)\n",
    "print(\"Job completed successfully!\")\n",
    "\n",
    "JSON(status_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f369e",
   "metadata": {},
   "source": [
    "## Retrieve Job Metadata\n",
    "\n",
    "The job metadata contains information about the processing results and output locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4741e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_metadata_s3 = status_response[\"outputConfiguration\"][\"s3Uri\"]\n",
    "print(f\"Retrieving job metadata from: {job_metadata_s3}\")\n",
    "\n",
    "job_metadata = json.loads(read_s3_object(job_metadata_s3))\n",
    "\n",
    "JSON(job_metadata, root='job_metadata', expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e70bf",
   "metadata": {},
   "source": [
    "## Explore Basic Standard Output Results\n",
    "\n",
    "Now let's examine the standard output that BDA generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255121d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the standard output path from metadata\n",
    "standard_output_path = job_metadata[\"output_metadata\"][0][\"segment_metadata\"][0][\"standard_output_path\"]\n",
    "print(f\"Standard output location: {standard_output_path}\")\n",
    "\n",
    "# Load the standard output\n",
    "standard_output = json.loads(read_s3_object(standard_output_path))\n",
    "\n",
    "JSON(standard_output, root=\"standard_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0a72c",
   "metadata": {},
   "source": [
    "**Note:** You may notice image references like `![LOGO](./image-id.png)` in the markdown output. BDA generates placeholder references for images it identifies in the document. The actual image files are only saved when using the `JSON+files` output configuration, which stores them in your S3 output bucket.\n",
    "\n",
    "# Part B: Advanced Standard Output Configuration\n",
    "\n",
    "Now let's explore how to configure standard output to extract much more detailed information using BDA projects.\n",
    "\n",
    "## Understanding Standard Output Configuration Options\n",
    "\n",
    "Before creating our project, let's understand the configuration options available for standard output:\n",
    "\n",
    "### Response Granularity\n",
    "\n",
    "Controls the level of detail in text extraction:\n",
    "- **DOCUMENT**: High-level document summary and statistics\n",
    "- **PAGE**: Content organized by page\n",
    "- **ELEMENT**: Semantic elements (paragraphs, headers, tables, figures)\n",
    "- **LINE**: Individual text lines with positioning\n",
    "- **WORD**: Word-level extraction with precise coordinates\n",
    "\n",
    "### Output Formats\n",
    "\n",
    "Multiple text representations:\n",
    "- **PLAIN_TEXT**: Clean text without formatting\n",
    "- **MARKDOWN**: Text with structural markdown elements (default)\n",
    "- **HTML**: Text with HTML formatting\n",
    "- **CSV**: Structured data for tables\n",
    "\n",
    "### Additional Features\n",
    "\n",
    "- **Bounding Boxes**: Coordinate information for visual positioning\n",
    "- **Generative Fields**: AI-generated descriptions and summaries\n",
    "- **Additional File Formats**: Export structured data as separate files\n",
    "\n",
    "## Prepare Complex Sample Document\n",
    "\n",
    "For this advanced section, we'll use a more complex document - a Treasury Statement with tables, figures, and structured content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a sample Treasury document\n",
    "document_url = \"https://fiscaldata.treasury.gov/static-data/published-reports/mts/MonthlyTreasuryStatement_202411.pdf\"\n",
    "local_file_name = \"data/documents/MonthlyTreasuryStatement_202411.pdf\"\n",
    "\n",
    "# Download and prepare the document\n",
    "file_path_local = download_document(document_url, local_file_name, verify=False)\n",
    "\n",
    "# Upload to S3\n",
    "file_name = Path(file_path_local).name\n",
    "document_s3_uri_advanced = f'{bda_s3_input_location}/{file_name}'\n",
    "target_s3_bucket_advanced, target_s3_key_advanced = get_bucket_and_key(document_s3_uri_advanced)\n",
    "\n",
    "s3_client.upload_file(local_file_name, target_s3_bucket_advanced, target_s3_key_advanced)\n",
    "\n",
    "print(f\"Document uploaded to S3: {document_s3_uri_advanced}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a2b84",
   "metadata": {},
   "source": [
    "### View Sample Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb2c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_pdf_pages(local_file_name, page_range=(0, 4), width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26e108",
   "metadata": {},
   "source": [
    "## Create Advanced Standard Output Configuration\n",
    "\n",
    "Now let's create a comprehensive standard output configuration that enables all available features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4079a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define comprehensive standard output configuration\n",
    "standard_output_config = {\n",
    "    \"document\": {\n",
    "        \"extraction\": {\n",
    "            # Enable all granularity levels\n",
    "            \"granularity\": {\"types\": [\"DOCUMENT\", \"PAGE\", \"ELEMENT\", \"LINE\", \"WORD\"]},\n",
    "            # Enable bounding boxes for visual positioning\n",
    "            \"boundingBox\": {\"state\": \"ENABLED\"}\n",
    "        },\n",
    "        # Enable AI-generated descriptions and summaries\n",
    "        \"generativeField\": {\"state\": \"ENABLED\"},\n",
    "        \"outputFormat\": {\n",
    "            # Enable all text formats\n",
    "            \"textFormat\": {\"types\": [\"PLAIN_TEXT\", \"MARKDOWN\", \"HTML\", \"CSV\"]},\n",
    "            # Export additional files (CSV for tables, etc.)\n",
    "            \"additionalFileFormat\": {\"state\": \"ENABLED\"}\n",
    "        }\n",
    "    },\n",
    "    # Include configurations for other modalities for completeness\n",
    "    \"image\": {\n",
    "        \"extraction\": {\n",
    "            \"category\": {\n",
    "                \"state\": \"ENABLED\",\n",
    "                \"types\": [\"CONTENT_MODERATION\", \"TEXT_DETECTION\"]\n",
    "            },\n",
    "            \"boundingBox\": {\"state\": \"ENABLED\"}\n",
    "        },\n",
    "        \"generativeField\": {\n",
    "            \"state\": \"ENABLED\",\n",
    "            \"types\": [\"IMAGE_SUMMARY\", \"IAB\"]\n",
    "        }\n",
    "    },\n",
    "    \"video\": {\n",
    "        \"extraction\": {\n",
    "            \"category\": {\n",
    "                \"state\": \"ENABLED\",\n",
    "                \"types\": [\"CONTENT_MODERATION\", \"TEXT_DETECTION\", \"TRANSCRIPT\"]\n",
    "            },\n",
    "            \"boundingBox\": {\"state\": \"ENABLED\"}\n",
    "        },\n",
    "        \"generativeField\": {\n",
    "            \"state\": \"ENABLED\",\n",
    "            \"types\": [\"VIDEO_SUMMARY\", \"CHAPTER_SUMMARY\", \"IAB\"]\n",
    "        }\n",
    "    },\n",
    "    \"audio\": {\n",
    "        \"extraction\": {\n",
    "            \"category\": {\n",
    "                \"state\": \"ENABLED\",\n",
    "                \"types\": ['AUDIO_CONTENT_MODERATION', 'TOPIC_CONTENT_MODERATION', 'TRANSCRIPT']\n",
    "            }\n",
    "        },\n",
    "        \"generativeField\": {\n",
    "            \"state\": \"ENABLED\",\n",
    "            \"types\": ['AUDIO_SUMMARY', 'TOPIC_SUMMARY', 'IAB']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Standard output configuration created with all features enabled:\")\n",
    "JSON(standard_output_config[\"document\"], expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110beb78",
   "metadata": {},
   "source": [
    "## Create BDA Project with Advanced Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"advanced_standard_output_project\"\n",
    "\n",
    "# Check if project already exists and delete it\n",
    "try:\n",
    "    projects_response = bda_client.list_data_automation_projects()\n",
    "    existing_projects = [p for p in projects_response[\"projects\"] if p[\"projectName\"] == project_name]\n",
    "    \n",
    "    if existing_projects:\n",
    "        print(f\"Deleting existing project: {existing_projects[0]['projectArn']}\")\n",
    "        bda_client.delete_data_automation_project(projectArn=existing_projects[0][\"projectArn\"])\n",
    "        time.sleep(2)\n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")\n",
    "\n",
    "# Create new project with advanced configuration\n",
    "response = bda_client.create_data_automation_project(\n",
    "    projectName=project_name,\n",
    "    projectDescription=\"Project demonstrating advanced standard output configuration\",\n",
    "    projectStage='LIVE',\n",
    "    standardOutputConfiguration=standard_output_config\n",
    ")\n",
    "\n",
    "project_arn = response[\"projectArn\"]\n",
    "print(f\"Created project: {project_arn}\")\n",
    "\n",
    "# Wait for project to be ready\n",
    "wait_for_project_completion(project_arn)\n",
    "JSON(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed42fcee",
   "metadata": {},
   "source": [
    "## Invoke BDA with Advanced Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2044838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Processing document with advanced configuration: {document_s3_uri_advanced}\")\n",
    "\n",
    "response = bda_runtime_client.invoke_data_automation_async(\n",
    "    inputConfiguration={\n",
    "        's3Uri': document_s3_uri_advanced\n",
    "    },\n",
    "    outputConfiguration={\n",
    "        's3Uri': bda_s3_output_location\n",
    "    },\n",
    "    dataAutomationConfiguration={\n",
    "        'dataAutomationProjectArn': project_arn,\n",
    "        'stage': 'LIVE'\n",
    "    },\n",
    "    dataAutomationProfileArn=f'arn:aws:bedrock:{current_region}:{account_id}:data-automation-profile/us.data-automation-v1'\n",
    ")\n",
    "\n",
    "invocation_arn_advanced = response['invocationArn']\n",
    "print(f\"Job submitted with invocation ARN: {invocation_arn_advanced}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c245bcf0",
   "metadata": {},
   "source": [
    "## Monitor Job and Retrieve Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86125712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for job completion\n",
    "status_response = wait_for_job_to_complete(invocation_arn=invocation_arn_advanced)\n",
    "\n",
    "if status_response['status'] == 'Success':\n",
    "    job_metadata_s3_location = status_response['outputConfiguration']['s3Uri']\n",
    "    print(f\"Job completed. Results at: {job_metadata_s3_location}\")\n",
    "else:\n",
    "    raise Exception(f\"Job failed: {status_response}\")\n",
    "\n",
    "# Load job metadata\n",
    "job_metadata_advanced = json.loads(read_s3_object(job_metadata_s3_location))\n",
    "JSON(job_metadata_advanced, root='job_metadata', expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd01b23a",
   "metadata": {},
   "source": [
    "## Explore Advanced Standard Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538701ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract standard output path\n",
    "asset_id = 0\n",
    "standard_output_path_advanced = next(\n",
    "    item[\"segment_metadata\"][0][\"standard_output_path\"] \n",
    "    for item in job_metadata_advanced[\"output_metadata\"] \n",
    "    if item['asset_id'] == asset_id\n",
    ")\n",
    "\n",
    "print(f\"Loading standard output from: {standard_output_path_advanced}\")\n",
    "standard_output_advanced = json.loads(read_s3_object(standard_output_path_advanced))\n",
    "\n",
    "standard_output_advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06248a",
   "metadata": {},
   "source": [
    "### Analyze Enhanced Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda01adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_advanced = standard_output_advanced['metadata']\n",
    "print(\"Enhanced Document Metadata:\")\n",
    "print(f\"- Sematic Modality: {metadata_advanced['semantic_modality']}\")\n",
    "print(f\"- Pages processed: {metadata_advanced['number_of_pages']}\")\n",
    "print(f\"- Processing time: {metadata_advanced.get('processing_time', 'N/A')}\")\n",
    "print(f\"- File size: {metadata_advanced.get('file_size', 'N/A')}\")\n",
    "\n",
    "JSON(metadata_advanced, root='enhanced_metadata', expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a3602",
   "metadata": {},
   "source": [
    "### Examine Document-Level Insights\n",
    "\n",
    "With generative fields enabled, we get AI-generated summaries and descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_info_advanced = standard_output_advanced['document']\n",
    "\n",
    "print(\"Document Statistics:\")\n",
    "stats = document_info_advanced['statistics']\n",
    "for key, value in stats.items():\n",
    "    print(f\"- {key}: {value}\")\n",
    "\n",
    "# Display AI-generated summary if available\n",
    "if 'summary' in document_info_advanced:\n",
    "    print(f\"\\nAI-Generated Document Summary:\")\n",
    "    print(document_info_advanced['summary'])\n",
    "\n",
    "if 'description' in document_info_advanced:\n",
    "    print(f\"\\nAI-Generated Document Description:\")\n",
    "    print(document_info_advanced['description'])\n",
    "\n",
    "document_info_advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf878949",
   "metadata": {},
   "source": [
    "### Explore Page-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7777bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_advanced = standard_output_advanced['pages']\n",
    "print(f\"Total pages analyzed: {len(pages_advanced)}\")\n",
    "\n",
    "# Analyze a specific page with rich content\n",
    "page_index = 4  # Choose a page with tables/figures\n",
    "if page_index < len(pages_advanced):\n",
    "    page = pages_advanced[page_index]\n",
    "    \n",
    "    print(f\"\\nPage {page_index + 1} Analysis:\")\n",
    "    print(f\"- Elements: {page['statistics']['element_count']}\")\n",
    "    print(f\"- Tables: {page['statistics']['table_count']}\")\n",
    "    print(f\"- Figures: {page['statistics']['figure_count']}\")\n",
    "    \n",
    "    # Display page content in markdown\n",
    "    print(f\"\\nPage Content (first 500 characters):\")\n",
    "    markdown_content = page['representation']['markdown']\n",
    "    print(markdown_content[:500] + \"...\")\n",
    "    \n",
    "    # Show bounding box information if available\n",
    "    if 'asset_metadata' in page:\n",
    "        print(f\"\\nPage Dimensions:\")\n",
    "        asset_meta = page['asset_metadata']\n",
    "        if 'bounding_box' in asset_meta:\n",
    "            bbox = asset_meta['bounding_box']\n",
    "            print(f\"- Width: {bbox.get('width', 'N/A')}\")\n",
    "            print(f\"- Height: {bbox.get('height', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc3c72",
   "metadata": {},
   "source": [
    "### Analyze Document Elements in Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_advanced = standard_output_advanced['elements']\n",
    "print(f\"Total elements extracted: {len(elements_advanced)}\")\n",
    "\n",
    "# Categorize elements by type\n",
    "element_summary = {}\n",
    "for element in elements_advanced:\n",
    "    element_type = element['type']\n",
    "    element_summary[element_type] = element_summary.get(element_type, 0) + 1\n",
    "\n",
    "print(\"\\nElement Distribution:\")\n",
    "for element_type, count in sorted(element_summary.items()):\n",
    "    print(f\"- {element_type}: {count}\")\n",
    "\n",
    "# Create a DataFrame for better analysis\n",
    "df_elements = pd.json_normalize(elements_advanced)\n",
    "print(f\"\\nElement DataFrame shape: {df_elements.shape}\")\n",
    "print(f\"Columns: {list(df_elements.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4dc037",
   "metadata": {},
   "source": [
    "### Examine Text Elements with Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7559ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for text elements with bounding boxes\n",
    "text_elements_advanced = [e for e in elements_advanced if e['type'] == 'TEXT' and 'locations' in e]\n",
    "\n",
    "print(f\"Text elements with positioning: {len(text_elements_advanced)}\")\n",
    "\n",
    "if text_elements_advanced:\n",
    "    # Show a sample text element with full details\n",
    "    sample_element = text_elements_advanced[0]\n",
    "    \n",
    "    print(\"\\nSample Text Element:\")\n",
    "    print(f\"- Subtype: {sample_element.get('subtype', 'N/A')}\")\n",
    "    print(f\"- Text: {sample_element['representation']['text'][:100]}...\")\n",
    "    \n",
    "    # Show bounding box information\n",
    "    if 'locations' in sample_element:\n",
    "        location = sample_element['locations'][0]\n",
    "        if 'bounding_box' in location:\n",
    "            bbox = location['bounding_box']\n",
    "            print(f\"- Position: ({bbox['left']}, {bbox['top']}) to ({bbox['left'] + bbox['width']}, {bbox['top'] + bbox['height']})\")\n",
    "    \n",
    "    JSON(sample_element, root='sample_text_element', expanded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30496c9f",
   "metadata": {},
   "source": [
    "### Analyze Table Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for table elements\n",
    "table_elements = [e for e in elements_advanced if e['type'] == 'TABLE']\n",
    "\n",
    "print(f\"Tables found: {len(table_elements)}\")\n",
    "\n",
    "if table_elements:\n",
    "    for i, table in enumerate(table_elements[:3]):  # Show first 3 tables\n",
    "        print(f\"\\nTable {i + 1}:\")\n",
    "        \n",
    "        # Show table metadata\n",
    "        if 'title' in table:\n",
    "            print(f\"- Title: {table['title']}\")\n",
    "        if 'summary' in table:\n",
    "            print(f\"- AI Summary: {table['summary']}\")\n",
    "        \n",
    "        # Show table structure\n",
    "        if 'representation' in table:\n",
    "            if 'csv' in table['representation']:\n",
    "                print(f\"- CSV data available\")\n",
    "                # Display first few rows of CSV data\n",
    "                csv_data = table['representation']['csv']\n",
    "                lines = csv_data.split('\\n')[:5]\n",
    "                for line in lines:\n",
    "                    print(f\"  {line}\")\n",
    "            \n",
    "            if 'html' in table['representation']:\n",
    "                print(f\"- HTML representation available\")\n",
    "        \n",
    "        # Show bounding box if available\n",
    "        if 'locations' in table and table['locations']:\n",
    "            location = table['locations'][0]\n",
    "            if 'bounding_box' in location:\n",
    "                bbox = location['bounding_box']\n",
    "                print(f\"- Position: Page {location['page_index']}, ({bbox['left']}, {bbox['top']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca02b96",
   "metadata": {},
   "source": [
    "### Analyze Figure Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6478e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for figure elements\n",
    "figure_elements = [e for e in elements_advanced if e['type'] == 'FIGURE']\n",
    "\n",
    "print(f\"Figures found: {len(figure_elements)}\")\n",
    "\n",
    "if figure_elements:\n",
    "    for i, figure in enumerate(figure_elements[:3]):  # Show first 3 figures\n",
    "        print(f\"\\nFigure {i + 1}:\")\n",
    "        \n",
    "        # Show figure metadata\n",
    "        if 'subtype' in figure:\n",
    "            print(f\"- Type: {figure['subtype']}\")\n",
    "        if 'title' in figure:\n",
    "            print(f\"- Title: {figure['title']}\")\n",
    "        if 'summary' in figure:\n",
    "            print(f\"- AI Description: {figure['summary']}\")\n",
    "        \n",
    "        # Show positioning\n",
    "        if 'locations' in figure and figure['locations']:\n",
    "            location = figure['locations'][0]\n",
    "            print(f\"- Page: {location['page_index']}\")\n",
    "            if 'bounding_box' in location:\n",
    "                bbox = location['bounding_box']\n",
    "                print(f\"- Position: ({bbox['left']}, {bbox['top']}) size: {bbox['width']}x{bbox['height']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5a8ab",
   "metadata": {},
   "source": [
    "### Explore Word-Level Granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if word-level data is available\n",
    "if 'text_words' in standard_output_advanced:\n",
    "    words = standard_output_advanced['text_words']\n",
    "    print(f\"Word-level extraction: {len(words)} words\")\n",
    "    \n",
    "    # Show sample words with positioning\n",
    "    sample_words = words[:10]\n",
    "    print(\"\\nSample words with positions:\")\n",
    "    for word in sample_words:\n",
    "        text = word['text']\n",
    "        if 'locations' in word and word['locations']:\n",
    "            location = word['locations'][0]\n",
    "            page = location['page_index']\n",
    "            if 'bounding_box' in location:\n",
    "                bbox = location['bounding_box']\n",
    "                print(f\"- '{text}' on page {page} at ({bbox['left']}, {bbox['top']})\")\n",
    "            else:\n",
    "                print(f\"- '{text}' on page {page}\")\n",
    "        else:\n",
    "            print(f\"- '{text}' (no position data)\")\n",
    "else:\n",
    "    print(\"Word-level data not available in this output\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9e95f",
   "metadata": {},
   "source": [
    "### Explore Line-Level Granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b076648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if line-level data is available\n",
    "if 'text_lines' in standard_output_advanced:\n",
    "    lines = standard_output_advanced['text_lines']\n",
    "    print(f\"Line-level extraction: {len(lines)} lines\")\n",
    "    \n",
    "    # Show sample lines\n",
    "    sample_lines = lines[:5]\n",
    "    print(\"\\nSample lines:\")\n",
    "    for i, line in enumerate(sample_lines):\n",
    "        text = line['text'][:80]\n",
    "        if 'locations' in line and line['locations']:\n",
    "            location = line['locations'][0]\n",
    "            page = location['page_index']\n",
    "            print(f\"Line {i+1} (page {page}): {text}...\")\n",
    "        else:\n",
    "            print(f\"Line {i+1}: {text}...\")\n",
    "else:\n",
    "    print(\"Line-level data not available in this output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19e15e",
   "metadata": {},
   "source": [
    "## Export and Analyze Structured Data\n",
    "\n",
    "Let's explore the additional file formats that were generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f30a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for additional files in the output\n",
    "print(\"Checking for additional exported files...\")\n",
    "\n",
    "# Look for CSV files and other exports\n",
    "# In a real scenario, these would be in the S3 output location\n",
    "# For now, let's analyze the CSV data embedded in table elements\n",
    "\n",
    "csv_tables = []\n",
    "for element in elements_advanced:\n",
    "    if element['type'] == 'TABLE' and 'representation' in element:\n",
    "        if 'csv' in element['representation']:\n",
    "            csv_data = element['representation']['csv']\n",
    "            csv_tables.append({\n",
    "                'title': element.get('title', f'Table {len(csv_tables) + 1}'),\n",
    "                'csv_data': csv_data,\n",
    "                'summary': element.get('summary', 'No summary available')\n",
    "            })\n",
    "\n",
    "print(f\"Found {len(csv_tables)} tables with CSV data\")\n",
    "\n",
    "# Convert first table to DataFrame for analysis\n",
    "if csv_tables:\n",
    "    first_table = csv_tables[0]\n",
    "    print(f\"\\nAnalyzing table: {first_table['title']}\")\n",
    "    print(f\"Summary: {first_table['summary']}\")\n",
    "    \n",
    "    # Convert CSV string to DataFrame\n",
    "    from io import StringIO\n",
    "    df = pd.read_csv(StringIO(first_table['csv_data']))\n",
    "    print(f\"Table shape: {df.shape}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e73bb29",
   "metadata": {},
   "source": [
    "## Compare Output Formats\n",
    "\n",
    "Let's compare the different text representations of the same content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find an element with multiple format representations\n",
    "multi_format_element = None\n",
    "for element in elements_advanced:\n",
    "    if 'representation' in element:\n",
    "        formats = list(element['representation'].keys())\n",
    "        if len(formats) > 1:\n",
    "            multi_format_element = element\n",
    "            break\n",
    "\n",
    "if multi_format_element:\n",
    "    print(\"Comparing different output formats for the same element:\")\n",
    "    print(f\"Element type: {multi_format_element['type']}\")\n",
    "    \n",
    "    rep = multi_format_element['representation']\n",
    "    \n",
    "    if 'text' in rep:\n",
    "        print(f\"\\nPlain Text (first 200 chars):\")\n",
    "        print(rep['text'][:200] + \"...\")\n",
    "    \n",
    "    if 'markdown' in rep:\n",
    "        print(f\"\\nMarkdown (first 200 chars):\")\n",
    "        print(rep['markdown'][:200] + \"...\")\n",
    "    \n",
    "    if 'html' in rep:\n",
    "        print(f\"\\nHTML (first 200 chars):\")\n",
    "        print(rep['html'][:200] + \"...\")\n",
    "    \n",
    "    if 'csv' in rep:\n",
    "        print(f\"\\nCSV (first 200 chars):\")\n",
    "        print(rep['csv'][:200] + \"...\")\n",
    "else:\n",
    "    print(\"No element found with multiple format representations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e63b3",
   "metadata": {},
   "source": [
    "## Performance and Configuration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the impact of different configuration options\n",
    "print(\"Configuration Impact Analysis:\")\n",
    "print(f\"- Total processing time: {metadata_advanced.get('processing_time', 'N/A')}\")\n",
    "print(f\"- Elements extracted: {len(elements_advanced)}\")\n",
    "print(f\"- Granularity levels enabled: {len(standard_output_config['document']['extraction']['granularity']['types'])}\")\n",
    "print(f\"- Output formats enabled: {len(standard_output_config['document']['outputFormat']['textFormat']['types'])}\")\n",
    "\n",
    "# Calculate data richness\n",
    "data_points = 0\n",
    "data_points += len(standard_output_advanced.get('pages', []))\n",
    "data_points += len(standard_output_advanced.get('elements', []))\n",
    "data_points += len(standard_output_advanced.get('text_lines', []))\n",
    "data_points += len(standard_output_advanced.get('text_words', []))\n",
    "\n",
    "print(f\"- Total data points extracted: {data_points}\")\n",
    "\n",
    "# Estimate storage requirements\n",
    "import sys\n",
    "output_size = sys.getsizeof(json.dumps(standard_output_advanced))\n",
    "print(f\"- Approximate output size: {output_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db9046d",
   "metadata": {},
   "source": [
    "## Best Practices and Recommendations\n",
    "\n",
    "Based on our exploration, here are key recommendations for using advanced standard output:\n",
    "\n",
    "### 1. Granularity Selection\n",
    "- Use **DOCUMENT + PAGE** for basic document understanding\n",
    "- Add **ELEMENT** for semantic structure analysis  \n",
    "- Include **LINE + WORD** only when precise positioning is needed\n",
    "\n",
    "### 2. Output Format Selection\n",
    "- **MARKDOWN**: Best for general text processing and display\n",
    "- **HTML**: Useful for web applications and rich formatting\n",
    "- **CSV**: Essential for table data analysis\n",
    "- **PLAIN_TEXT**: Minimal overhead for simple text extraction\n",
    "\n",
    "### 3. Feature Enablement\n",
    "- **Bounding Boxes**: Enable for layout analysis and visual applications\n",
    "- **Generative Fields**: Enable for AI-powered insights and summaries\n",
    "- **Additional File Formats**: Enable for structured data export\n",
    "\n",
    "### 4. Performance Considerations\n",
    "- More granularity = longer processing time + larger output\n",
    "- Balance feature richness with processing requirements\n",
    "- Consider caching results for repeated analysis\n",
    "\n",
    "## Understanding BDA Workflow\n",
    "\n",
    "Let's summarize what we've learned about the BDA workflow:\n",
    "\n",
    "1. **Input Configuration**: Specify the S3 location of your document\n",
    "2. **Output Configuration**: Define where results should be stored\n",
    "3. **Processing**: BDA analyzes the document using AI models\n",
    "4. **Results**: Structured output is generated and stored in S3\n",
    "\n",
    "The standard output provides a rich foundation for document understanding, from basic extraction to advanced configuration with multiple granularity levels and output formats.\n",
    "\n",
    "## Key Concepts Review\n",
    "\n",
    "**Standard Output Components:**\n",
    "- **Metadata**: Basic document information and processing details\n",
    "- **Document**: High-level statistics and summaries\n",
    "- **Pages**: Page-by-page content in markdown format\n",
    "- **Elements**: Semantic elements like text blocks, tables, and figures\n",
    "\n",
    "**BDA Processing Flow:**\n",
    "1. Upload document to S3\n",
    "2. Submit processing job via `InvokeDataAutomationAsync`\n",
    "3. Monitor job status with `GetDataAutomationStatus`\n",
    "4. Retrieve results from S3 output location\n",
    "\n",
    "**Advanced Configuration Options:**\n",
    "- **Granularity Levels**: Control detail level from document to word-level\n",
    "- **Output Formats**: Multiple text representations (markdown, HTML, CSV, plain text)\n",
    "- **Bounding Boxes**: Visual positioning information\n",
    "- **Generative Fields**: AI-powered descriptions and summaries\n",
    "\n",
    "## Clean Up\n",
    "\n",
    "Remove the sample files and job outputs to keep your S3 bucket clean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27edb62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up resources\n",
    "print(\"Cleaning up resources...\")\n",
    "\n",
    "# Delete the uploaded documents\n",
    "s3_client.delete_object(Bucket=target_s3_bucket, Key=target_s3_key)\n",
    "s3_client.delete_object(Bucket=target_s3_bucket_advanced, Key=target_s3_key_advanced)\n",
    "\n",
    "# Delete the project\n",
    "bda_client.delete_data_automation_project(projectArn=project_arn)\n",
    "\n",
    "# Delete job outputs\n",
    "bda_s3_job_location = str(Path(job_metadata_s3).parent).replace(\"s3:/\", \"s3://\")\n",
    "bda_s3_job_location_advanced = str(Path(job_metadata_s3_location).parent).replace(\"s3:/\", \"s3://\")\n",
    "\n",
    "print(f\"Job output locations:\")\n",
    "print(f\"- Basic: {bda_s3_job_location}\")\n",
    "print(f\"- Advanced: {bda_s3_job_location_advanced}\")\n",
    "\n",
    "# Uncomment the following lines to delete job outputs:\n",
    "# !aws s3 rm {bda_s3_job_location} --recursive\n",
    "# !aws s3 rm {bda_s3_job_location_advanced} --recursive\n",
    "\n",
    "print(\"Cleanup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebfc623",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how to:\n",
    "\n",
    "1. **Set up BDA**: Configure AWS clients and permissions for document processing\n",
    "2. **Process Basic Documents**: Use default standard output with simple documents\n",
    "3. **Create Advanced Projects**: Configure projects with comprehensive standard output settings\n",
    "4. **Analyze Complex Documents**: Process documents with tables, figures, and structured content\n",
    "5. **Work with Multiple Granularities**: Extract data at document, page, element, line, and word levels\n",
    "6. **Use Multiple Output Formats**: Generate content in markdown, HTML, CSV, and plain text\n",
    "7. **Enable Enhanced Features**: Utilize bounding boxes and generative fields for richer insights\n",
    "\n",
    "The progression from basic to advanced standard output demonstrates BDA's flexibility in handling different document processing requirements. You can now choose the appropriate configuration level based on your specific use case, balancing processing time and resource requirements with the richness of extracted data.\n",
    "\n",
    "In the next lab, we'll explore custom outputs and blueprints for targeted data extraction from specific document types."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
