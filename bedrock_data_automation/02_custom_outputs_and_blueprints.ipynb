{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc572a62",
   "metadata": {},
   "source": [
    "# Lab 2: Custom Outputs and Blueprints\n",
    "\n",
    "While standard output provides rich document insights, many business applications require extracting specific, structured data tailored to particular document types. Amazon Bedrock Data Automation's custom output feature uses blueprints to define exactly what information to extract from documents.\n",
    "\n",
    "Blueprints are instruction sets that guide BDA to extract specific fields, validate data formats, and transform content according to your business requirements. This lab explores how to create custom blueprints, use pre-built catalog blueprints, and build projects that can handle multiple document types automatically.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "- Understand blueprint concepts and structure\n",
    "- Create custom blueprints for specific document types\n",
    "- Use pre-built catalog blueprints for common documents\n",
    "- Build projects with multiple blueprints for document classification\n",
    "- Enable document splitting for multi-document files\n",
    "- Analyze custom output results and confidence scores\n",
    "- Transform extracted data for downstream applications\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Complete Lab 1 or ensure you have:\n",
    "- Understanding of BDA standard output and projects\n",
    "- Experience with BDA API operations\n",
    "- Familiarity with JSON schema structures\n",
    "- Knowledge of document processing workflows\n",
    "\n",
    "### Install Required Libraries\n",
    "\n",
    "The dependencies needed for this lab have already been installed when you set up the `venv` environment. \n",
    "\n",
    "If you are running the notebook in your own account, you need to install the following dependencies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc654bc",
   "metadata": {},
   "source": [
    "```python\n",
    "%pip install --no-warn-conflicts boto3 itables==2.2.4 PyPDF2==3.0.1 --upgrade -q\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca6a82",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before we get to the part where we invoke BDA with our sample artifacts, let's setup some parameters and configuration that will be used throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84729f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from IPython.display import JSON, IFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ba935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper_functions import (\n",
    "    get_bucket_and_key,\n",
    "    read_s3_object,\n",
    "    wait_for_job_to_complete,\n",
    "    wait_for_project_completion,\n",
    "    create_or_update_blueprint,\n",
    "    transform_custom_output,\n",
    "    preview_pdf_pages\n",
    ")\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "current_region = boto3.session.Session().region_name\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "\n",
    "# Initialize Bedrock Data Automation client\n",
    "bda_client = boto3.client('bedrock-data-automation')\n",
    "bda_runtime_client = boto3.client('bedrock-data-automation-runtime')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Define bucket name\n",
    "bda_bucket = f\"pace-bootcamp-bda-bucket-{account_id}-{current_region}\"\n",
    "\n",
    "bda_s3_input_location = f's3://{bda_bucket}/bda/input'\n",
    "bda_s3_output_location = f's3://{bda_bucket}/bda/output'\n",
    "\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"Region: {current_region}\")\n",
    "print(f\"S3 bucket: {bda_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5d5818",
   "metadata": {},
   "source": [
    "## Prepare Sample Document\n",
    "\n",
    "For this lab, we use a sample `Medical Claim` pack. The pack contains multiple classes of document supporting the claim. We will upload the sample file to S3 and use a combination of catalog and custom blueprints to extract the contents of each document class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f63a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_download_path = 'data/documents'\n",
    "local_file_name = 'claims-pack.pdf'\n",
    "local_file_path = os.path.join(local_download_path, local_file_name)\n",
    "\n",
    "document_s3_uri = f'{bda_s3_input_location}/{local_file_name}'\n",
    "\n",
    "target_s3_bucket, target_s3_key = get_bucket_and_key(document_s3_uri)\n",
    "s3_client.upload_file(local_file_path, target_s3_bucket, target_s3_key)\n",
    "\n",
    "print(f\"Downloaded file to: {local_file_path}\")\n",
    "print(f\"Uploaded file to S3: {target_s3_key}\")\n",
    "print(f\"document_s3_uri: {document_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8588a4da",
   "metadata": {},
   "source": [
    "### View Sample Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaea241",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_pdf_pages(local_file_path, page_range=(0, 4), width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea4a006",
   "metadata": {},
   "source": [
    "## Understanding Blueprints\n",
    "\n",
    "Blueprints define the structure and fields you want to extract from documents. They use JSON schema format to specify:\n",
    "\n",
    "- **Field names and types**: What data to extract and its expected format\n",
    "- **Instructions**: How to locate and interpret the information\n",
    "- **Validation rules**: Data type constraints and formatting requirements\n",
    "\n",
    "Let's examine a sample blueprint structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/blueprints/claims_form.json') as f:\n",
    "    claims_schema = json.load(f)\n",
    "\n",
    "print(\"Sample Blueprint Structure (first few fields):\")\n",
    "sample_fields = dict(list(claims_schema['properties'].items())[:5])\n",
    "JSON(sample_fields, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec720ac",
   "metadata": {},
   "source": [
    "## Create Custom Blueprints and Project\n",
    "\n",
    "Our sample file contains multiple document types. We'll create custom blueprints for the most common medical claim documents and combine them with relevant catalog blueprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab595e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create focused set of custom blueprints\n",
    "blueprints = [\n",
    "    {\n",
    "        \"name\": 'claim-form',\n",
    "        \"description\": 'Blueprint for Medical Claim form CMS 1500',\n",
    "        \"type\": 'DOCUMENT',\n",
    "        \"stage\": 'LIVE',\n",
    "        \"schema_path\": 'data/blueprints/claims_form.json'\n",
    "    },\n",
    "    {\n",
    "        \"name\": 'hospital-discharge-report',\n",
    "        \"description\": 'Blueprint for Hospital discharge summary report',\n",
    "        \"type\": 'DOCUMENT',\n",
    "        \"stage\": 'LIVE',\n",
    "        \"schema_path\": 'data/blueprints/discharge_summary.json'\n",
    "    }\n",
    "]\n",
    "\n",
    "blueprint_arns = []\n",
    "for blueprint in blueprints:\n",
    "    with open(blueprint['schema_path']) as f:\n",
    "        blueprint_schema = json.load(f)\n",
    "        blueprint_arn = create_or_update_blueprint(\n",
    "            blueprint_name=blueprint['name'], \n",
    "            blueprint_description=blueprint['description'], \n",
    "            blueprint_type=blueprint['type'],\n",
    "            blueprint_stage=blueprint['stage'],\n",
    "            blueprint_schema=blueprint_schema\n",
    "        )\n",
    "        blueprint_arns += [blueprint_arn]\n",
    "\n",
    "print(f\"Created {len(blueprint_arns)} custom blueprints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b605854",
   "metadata": {},
   "source": [
    "## Create Data Project for Multi-Document Processing\n",
    "\n",
    "With custom blueprints created, we can now create our data project. We add multiple blueprints to handle the document types we expect in the claim pack.\n",
    "\n",
    "Key features:\n",
    "- Multiple custom blueprints for medical documents\n",
    "- Relevant catalog blueprints for supporting documents\n",
    "- Document splitter enabled for multi-document processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bda_project_name = 'document-custom-output-multiple-blueprints'\n",
    "bda_project_stage = 'LIVE'\n",
    "\n",
    "# Standard output configuration for basic document analysis\n",
    "standard_output_configuration = {\n",
    "    'document': {\n",
    "        'extraction': {\n",
    "            'granularity': {'types': ['DOCUMENT', 'PAGE']},\n",
    "            'boundingBox': {'state': 'ENABLED'}\n",
    "        },\n",
    "        'generativeField': {'state': 'ENABLED'},\n",
    "        'outputFormat': {\n",
    "            'textFormat': {'types': ['MARKDOWN']},\n",
    "            'additionalFileFormat': {'state': 'ENABLED'}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Custom output configuration with focused blueprint selection\n",
    "custom_output_configuration = {\n",
    "    \"blueprints\": [\n",
    "        # Medical-relevant catalog blueprints\n",
    "        {\n",
    "            'blueprintArn': f'arn:aws:bedrock:{current_region}:aws:blueprint/bedrock-data-automation-public-prescription-label',\n",
    "            'blueprintStage': 'LIVE'\n",
    "        },\n",
    "        {\n",
    "            'blueprintArn': f'arn:aws:bedrock:{current_region}:aws:blueprint/bedrock-data-automation-public-us-medical-insurance-card',\n",
    "            'blueprintStage': 'LIVE'\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Add our custom blueprints\n",
    "custom_output_configuration['blueprints'] += [\n",
    "    {\n",
    "        'blueprintArn': blueprint_arn,\n",
    "        'blueprintStage': 'LIVE'\n",
    "    } for blueprint_arn in blueprint_arns\n",
    "]\n",
    "\n",
    "# Enable document splitting for multi-document files\n",
    "override_configuration = {'document': {'splitter': {'state': 'ENABLED'}}}\n",
    "\n",
    "print(f\"Project will use {len(custom_output_configuration['blueprints'])} blueprints:\")\n",
    "for i, bp in enumerate(custom_output_configuration['blueprints']):\n",
    "    print(f\"  {i+1}. {bp['blueprintArn'].split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f12a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or update the project\n",
    "list_project_response = bda_client.list_data_automation_projects(\n",
    "    projectStageFilter=bda_project_stage)\n",
    "\n",
    "project = next((project for project in list_project_response['projects']\n",
    "               if project['projectName'] == bda_project_name), None)\n",
    "\n",
    "if not project:\n",
    "    response = bda_client.create_data_automation_project(\n",
    "        projectName=bda_project_name,\n",
    "        projectDescription='Document processing combining blueprints with data projects',\n",
    "        projectStage=bda_project_stage,\n",
    "        standardOutputConfiguration=standard_output_configuration,\n",
    "        customOutputConfiguration=custom_output_configuration,\n",
    "        overrideConfiguration=override_configuration\n",
    "    )\n",
    "else:\n",
    "    response = bda_client.update_data_automation_project(\n",
    "        projectArn=project['projectArn'],\n",
    "        standardOutputConfiguration=standard_output_configuration,\n",
    "        customOutputConfiguration=custom_output_configuration,\n",
    "        overrideConfiguration=override_configuration\n",
    "    )\n",
    "\n",
    "project_arn = response['projectArn']\n",
    "print(f\"Project ARN: {project_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042e4dbd",
   "metadata": {},
   "source": [
    "### Wait for Project Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c4618",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_project_completion(project_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1844e99",
   "metadata": {},
   "source": [
    "## Invoke Data Automation\n",
    "\n",
    "With the data project configured, we can now invoke data automation for our sample document. When we submit the document for processing, BDA scans the file and splits it into individual documents based on context and matches it against the list of blueprints provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86afcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bda_runtime_client.invoke_data_automation_async(\n",
    "    inputConfiguration={\n",
    "        's3Uri': document_s3_uri\n",
    "    },\n",
    "    outputConfiguration={\n",
    "        's3Uri': bda_s3_output_location\n",
    "    },\n",
    "    dataAutomationConfiguration={\n",
    "        'dataAutomationProjectArn': project_arn,\n",
    "        'stage': 'LIVE'\n",
    "    }, \n",
    "    dataAutomationProfileArn = f'arn:aws:bedrock:{current_region}:{account_id}:data-automation-profile/us.data-automation-v1'\n",
    ")\n",
    "\n",
    "invocationArn = response['invocationArn']\n",
    "print(f'Invoked data automation job with invocation arn {invocationArn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835d8422",
   "metadata": {},
   "source": [
    "## Monitor Job Status and Retrieve Results\n",
    "\n",
    "We can check the status and monitor the progress of the invocation job using the `GetDataAutomationStatus`. This API takes the invocation arn we retrieved from the response to the `InvokeDataAutomationAsync` operation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_response = wait_for_job_to_complete(invocation_arn=invocationArn)\n",
    "\n",
    "if status_response['status'] == 'Success':\n",
    "    job_metadata_s3_location = status_response['outputConfiguration']['s3Uri']\n",
    "    print(f\"Job completed successfully!\")\n",
    "    print(f\"Results location: {job_metadata_s3_location}\")\n",
    "else:\n",
    "    raise Exception(f'Invocation Job Error, error_type={status_response[\"error_type\"]}, error_message={status_response[\"error_message\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d228c4e5",
   "metadata": {},
   "source": [
    "## Analyze Job Metadata and Results\n",
    "\n",
    "The job metadata contains the S3 URIs for the standard output, custom output and the status of custom output. The custom output status could be either `MATCH` or `NO_MATCH`. `MATCH` indicates BDA was able to find a matching blueprint for the specific segment from the list of blueprints we associated with the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3abf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_metadata = json.loads(read_s3_object(job_metadata_s3_location))\n",
    "\n",
    "# Create summary table of segments\n",
    "job_metadata_table = pd.DataFrame(job_metadata['output_metadata'][0]['segment_metadata']).fillna('')\n",
    "job_metadata_table.index.name = 'Segment Index'\n",
    "\n",
    "print(\"Job Metadata Summary:\")\n",
    "print(job_metadata_table.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79ee9e",
   "metadata": {},
   "source": [
    "## Explore Custom Output Results\n",
    "\n",
    "As we can see in the job metadata, BDA creates a segment for each individual document that it identified in the file. Each segment has details on the matched blueprint and the results of the extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77227c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_id = 0\n",
    "segments_metadata = next(item[\"segment_metadata\"]\n",
    "                        for item in job_metadata[\"output_metadata\"] \n",
    "                        if item['asset_id'] == asset_id)\n",
    "\n",
    "# Load standard and custom outputs for each segment\n",
    "standard_outputs = [\n",
    "    json.loads(read_s3_object(segment_metadata.get('standard_output_path')))\n",
    "    for segment_metadata in segments_metadata\n",
    "]\n",
    "\n",
    "custom_outputs = [\n",
    "    json.loads(read_s3_object(segment_metadata.get('custom_output_path'))) \n",
    "    if segment_metadata.get('custom_output_status') == 'MATCH' else None \n",
    "    for segment_metadata in segments_metadata\n",
    "]\n",
    "\n",
    "print(f\"Processed {len(segments_metadata)} document segments\")\n",
    "print(f\"Found {sum(1 for co in custom_outputs if co is not None)} blueprint matches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50119ae6",
   "metadata": {},
   "source": [
    "### Analyze Blueprint Matching Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6fb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary of custom outputs\n",
    "summary_data = []\n",
    "for i, custom_output in enumerate(custom_outputs):\n",
    "    if custom_output:\n",
    "        matched_blueprint = custom_output.get('matched_blueprint', {})\n",
    "        summary_data.append({\n",
    "            'segment': i,\n",
    "            'matched_blueprint': matched_blueprint.get('name', 'Unknown'),\n",
    "            'confidence': matched_blueprint.get('confidence', 'N/A'),\n",
    "            'document_type': custom_output.get('document_class', {}).get('type', 'Unknown')\n",
    "        })\n",
    "    else:\n",
    "        summary_data.append({\n",
    "            'segment': i,\n",
    "            'matched_blueprint': 'No Match',\n",
    "            'confidence': 'N/A',\n",
    "            'document_type': 'Unknown'\n",
    "        })\n",
    "\n",
    "custom_outputs_table = pd.DataFrame(summary_data)\n",
    "print(\"Blueprint Matching Results:\")\n",
    "print(custom_outputs_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5434a",
   "metadata": {},
   "source": [
    "## Extract and Transform Custom Output Data\n",
    "\n",
    "Now let's process the extracted data and examine the structured information that BDA extracted using our blueprints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and display extracted data for matched segments\n",
    "for i, (custom_output, standard_output) in enumerate(zip(custom_outputs, standard_outputs)):\n",
    "    if custom_output:\n",
    "        matched_blueprint = custom_output.get('matched_blueprint', {})\n",
    "        blueprint_name = matched_blueprint.get('name', 'Unknown')\n",
    "        confidence = matched_blueprint.get('confidence', 'N/A')\n",
    "        \n",
    "        print(f\"\\n=== Segment {i+1}: {blueprint_name} (Confidence: {confidence}) ===\")\n",
    "        \n",
    "        # Transform the custom output with confidence scores\n",
    "        inference_result = custom_output.get('inference_result', {})\n",
    "        explainability_info = custom_output.get('explainability_info', [{}])[0] if custom_output.get('explainability_info') else {}\n",
    "        \n",
    "        result = transform_custom_output(inference_result, explainability_info)\n",
    "        \n",
    "        # Display extracted form fields\n",
    "        if result['forms']:\n",
    "            print(\"\\nExtracted Form Fields:\")\n",
    "            field_count = 0\n",
    "            for field_name, field_data in result['forms'].items():\n",
    "                if field_count >= 10:  # Limit display to first 10 fields\n",
    "                    print(f\"  ... and {len(result['forms']) - 10} more fields\")\n",
    "                    break\n",
    "                \n",
    "                if isinstance(field_data, dict) and 'value' in field_data:\n",
    "                    confidence_str = f\" (confidence: {field_data.get('confidence', 'N/A')})\" if 'confidence' in field_data else \"\"\n",
    "                    print(f\"  {field_name}: {field_data['value']}{confidence_str}\")\n",
    "                else:\n",
    "                    print(f\"  {field_name}: {field_data}\")\n",
    "                field_count += 1\n",
    "        \n",
    "        # Display extracted tables\n",
    "        if result['tables']:\n",
    "            print(f\"\\nExtracted Tables: {len(result['tables'])} found\")\n",
    "            for table_name, table_data in result['tables'].items():\n",
    "                print(f\"  {table_name}: {len(table_data)} rows\")\n",
    "                if table_data and len(table_data) > 0:\n",
    "                    print(f\"    Sample row: {table_data[0]}\")\n",
    "    else:\n",
    "        print(f\"\\n=== Segment {i+1}: No Blueprint Match ===\")\n",
    "        # Show basic document info from standard output\n",
    "        doc_stats = standard_output.get('document', {}).get('statistics', {})\n",
    "        print(f\"Document elements: {doc_stats.get('element_count', 'N/A')}\")\n",
    "        print(f\"Tables: {doc_stats.get('table_count', 'N/A')}\")\n",
    "        print(f\"Figures: {doc_stats.get('figure_count', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3062a72",
   "metadata": {},
   "source": [
    "## Understanding Confidence Scores\n",
    "\n",
    "Confidence scores help you understand how certain BDA is about the extracted information. This is crucial for production applications where data quality matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8800b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze confidence scores across all extractions\n",
    "confidence_analysis = []\n",
    "\n",
    "for i, custom_output in enumerate(custom_outputs):\n",
    "    if custom_output:\n",
    "        blueprint_confidence = custom_output.get('matched_blueprint', {}).get('confidence', 0)\n",
    "        \n",
    "        # Analyze field-level confidence if available\n",
    "        explainability_info = custom_output.get('explainability_info', [{}])[0] if custom_output.get('explainability_info') else {}\n",
    "        \n",
    "        field_confidences = []\n",
    "        for field_name, field_info in explainability_info.items():\n",
    "            if isinstance(field_info, dict) and 'confidence' in field_info:\n",
    "                field_confidences.append(field_info['confidence'])\n",
    "        \n",
    "        avg_field_confidence = sum(field_confidences) / len(field_confidences) if field_confidences else 0\n",
    "        \n",
    "        confidence_analysis.append({\n",
    "            'segment': i,\n",
    "            'blueprint_confidence': blueprint_confidence,\n",
    "            'avg_field_confidence': avg_field_confidence,\n",
    "            'field_count': len(field_confidences)\n",
    "        })\n",
    "\n",
    "if confidence_analysis:\n",
    "    confidence_df = pd.DataFrame(confidence_analysis)\n",
    "    print(\"Confidence Score Analysis:\")\n",
    "    print(confidence_df.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"Average blueprint confidence: {confidence_df['blueprint_confidence'].mean():.3f}\")\n",
    "    print(f\"Average field confidence: {confidence_df['avg_field_confidence'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d43968",
   "metadata": {},
   "source": [
    "## Use Case: Data Validation and Quality Assurance\n",
    "\n",
    "Let's demonstrate how to use confidence scores for data quality assurance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983567ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_extraction_quality(custom_outputs, min_blueprint_confidence=0.8, min_field_confidence=0.7):\n",
    "    \"\"\"Validate extraction quality based on confidence thresholds\"\"\"\n",
    "    validation_results = []\n",
    "    \n",
    "    for i, custom_output in enumerate(custom_outputs):\n",
    "        if not custom_output:\n",
    "            validation_results.append({\n",
    "                'segment': i,\n",
    "                'status': 'NO_MATCH',\n",
    "                'blueprint_confidence': 0,\n",
    "                'issues': ['No blueprint matched']\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        blueprint_confidence = custom_output.get('matched_blueprint', {}).get('confidence', 0)\n",
    "        issues = []\n",
    "        \n",
    "        # Check blueprint confidence\n",
    "        if blueprint_confidence < min_blueprint_confidence:\n",
    "            issues.append(f'Low blueprint confidence: {blueprint_confidence:.3f}')\n",
    "        \n",
    "        # Check field-level confidence\n",
    "        explainability_info = custom_output.get('explainability_info', [{}])[0] if custom_output.get('explainability_info') else {}\n",
    "        low_confidence_fields = []\n",
    "        \n",
    "        for field_name, field_info in explainability_info.items():\n",
    "            if isinstance(field_info, dict) and 'confidence' in field_info:\n",
    "                if field_info['confidence'] < min_field_confidence:\n",
    "                    low_confidence_fields.append(f\"{field_name}({field_info['confidence']:.3f})\")\n",
    "        \n",
    "        if low_confidence_fields:\n",
    "            issues.append(f'Low confidence fields: {\", \".join(low_confidence_fields[:3])}{\"...\" if len(low_confidence_fields) > 3 else \"\"}')\n",
    "        \n",
    "        status = 'PASS' if not issues else 'REVIEW_NEEDED'\n",
    "        \n",
    "        validation_results.append({\n",
    "            'segment': i,\n",
    "            'status': status,\n",
    "            'blueprint_confidence': blueprint_confidence,\n",
    "            'issues': issues\n",
    "        })\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "# Run validation\n",
    "validation_results = validate_extraction_quality(custom_outputs)\n",
    "\n",
    "print(\"Data Quality Validation Results:\")\n",
    "for result in validation_results:\n",
    "    print(f\"Segment {result['segment']}: {result['status']}\")\n",
    "    if result['issues']:\n",
    "        for issue in result['issues']:\n",
    "            print(f\"  - {issue}\")\n",
    "\n",
    "# Summary statistics\n",
    "total_segments = len(validation_results)\n",
    "passed_segments = sum(1 for r in validation_results if r['status'] == 'PASS')\n",
    "print(f\"\\nValidation Summary: {passed_segments}/{total_segments} segments passed quality checks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c884754b",
   "metadata": {},
   "source": [
    "## Best Practices for Blueprint Design\n",
    "\n",
    "Based on our analysis, here are key recommendations for creating effective blueprints:\n",
    "\n",
    "### 1. Field Selection\n",
    "- Focus on essential fields for your use case\n",
    "- Use clear, descriptive field names\n",
    "- Include proper data type specifications\n",
    "\n",
    "### 2. Instruction Quality\n",
    "- Provide specific location hints (e.g., \"item 24A\", \"top right corner\")\n",
    "- Use consistent terminology\n",
    "- Include format specifications (e.g., \"YYYY-MM-DD format\")\n",
    "\n",
    "### 3. Confidence Monitoring\n",
    "- Set appropriate confidence thresholds for your use case\n",
    "- Monitor field-level confidence for critical data\n",
    "- Implement review workflows for low-confidence extractions\n",
    "\n",
    "### 4. Blueprint Testing\n",
    "- Test with diverse document samples\n",
    "- Validate against known good data\n",
    "- Iterate based on confidence score analysis\n",
    "\n",
    "## Clean Up\n",
    "\n",
    "Let's delete uploaded sample file from S3 input directory and the generated job output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete S3 File\n",
    "s3_client.delete_object(Bucket=target_s3_bucket, Key=target_s3_key)\n",
    "\n",
    "# Delete custom blueprints\n",
    "for blueprint_arn in blueprint_arns:\n",
    "    try:\n",
    "        bda_client.delete_blueprint(blueprintArn=blueprint_arn)\n",
    "        print(f\"Deleted blueprint: {blueprint_arn}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Could not delete blueprint {blueprint_arn}: {e}\")\n",
    "\n",
    "# Delete project\n",
    "bda_client.delete_data_automation_project(projectArn=project_arn)\n",
    "\n",
    "# Delete BDA job output\n",
    "bda_s3_job_location = str(Path(job_metadata_s3_location).parent).replace(\"s3:/\",\"s3://\")\n",
    "print(f\"Job output location: {bda_s3_job_location}\")\n",
    "\n",
    "# Uncomment to delete job outputs:\n",
    "# !aws s3 rm {bda_s3_job_location} --recursive\n",
    "\n",
    "print(\"Cleanup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2780f1c2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how to:\n",
    "\n",
    "1. **Create Custom Blueprints**: Define structured extraction schemas for specific document types\n",
    "2. **Use Catalog Blueprints**: Leverage pre-built blueprints for common document formats\n",
    "3. **Build Multi-Blueprint Projects**: Handle multiple document types in a single processing workflow\n",
    "4. **Enable Document Splitting**: Process multi-document files automatically\n",
    "5. **Analyze Confidence Scores**: Understand and validate extraction quality\n",
    "6. **Implement Quality Assurance**: Build validation workflows for production use\n",
    "\n",
    "The combination of custom and catalog blueprints with document splitting enables BDA to handle complex, real-world document processing scenarios. You can now build applications that automatically classify documents, extract structured data, and validate results based on confidence scores.\n",
    "\n",
    "For a deeper dive into intelligent document processing, explore industry-specific use cases and advanced blueprint patterns in production environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
