{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Repeatable Patterns\n",
    "\n",
    "> **⚠️ Browser Compatibility Notice**: This lab requires **Google Chrome browser** for optimal performance. Please ensure you're using Chrome before proceeding.\n",
    "\n",
    "> **Important**: If you haven't completed Lab 1, please ensure you've followed the Code Setup Instructions in Lab 1 before proceeding.\n",
    "\n",
    "In this section, we'll explore common reusable patterns for integrating Nova Sonic voice chat, including:\n",
    "\n",
    "- Integrate with MCP\n",
    "- Integrate with Strands Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Trade-offs in Sonic Agentic Workflow Integration\n",
    "\n",
    "The **MCP lab** demonstrates a pattern that leverages Nova Sonic's built-in reasoning model to manage tool selection and directly invoke external MCP tools. This approach is well-suited for use cases requiring relatively simple toolUse definitions. Its key advantage is reduced latency, as all reasoning and generation happen within Sonic.\n",
    "\n",
    "The **Strands Agent samples** illustrate a different pattern: keeping the toolUse definition within Sonic simple while delegating reasoning and generation to an external agentic workflow. This approach offers greater flexibility and allows users to reuse existing workflows with minimal refactoring. However, it typically introduces higher latency due to redundant steps in tool selection, reasoning, and generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate with MCP\n",
    "\n",
    "[Model Context Protocol (MCP)](https://modelcontextprotocol.io/docs/getting-started/intro) is an open standard that enables AI models to access external data and tools. This sample integrates with MCP to support location-based queries using the [AWS Location Service MCP server](https://github.com/awslabs/mcp?tab=readme-ov-file#aws-location-service-mcp-server).\n",
    "\n",
    "### Tool Routing by Nova Sonic\n",
    "\n",
    "![Sonic MCP Processing](static/image-36.png)\n",
    "\n",
    "The workflow:\n",
    "1. Users ask questions via voice chat, such as: \"Where is the largest zoo in Seattle?\"\n",
    "2. Nova Sonic triggers a toolUse event with the specified ToolName (e.g., `search_places`, `search_nearby`)\n",
    "3. Nova Sonic calls the MCP server tool directly and retrieves the raw response\n",
    "4. Nova Sonic processes the Tool response and generates output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Configuration\n",
    "\n",
    "Located at: [`react-client/src/helper/s2sEvents.js`](react-client/src/helper/s2sEvents.js#L28-L67) - see the `DEFAULT_TOOL_CONFIG` starting at line 28\n",
    "\n",
    "```javascript\n",
    "{\n",
    "  \"toolSpec\": {\n",
    "    \"name\": \"locationMcpTool\",\n",
    "    \"description\": \"Access location services to find places, addresses, nearby locations.\",\n",
    "    \"inputSchema\": {\n",
    "      \"json\": JSON.stringify({\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"tool\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The function name to search the location service. One of: search_places, get_place, search_nearby, reverse_geocode\",\n",
    "          },\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The search query to find relevant information\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "      })\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle MCP ToolUse Event\n",
    "\n",
    "In [`python-server/s2s_session_manager.py`](python-server/s2s_session_manager.py#L295-L298) - see the MCP integration logic around line 295:\n",
    "\n",
    "```python\n",
    "# MCP integration - location search                        \n",
    "if toolName == \"getlocationtool\":\n",
    "    if self.mcp_loc_client:\n",
    "        result = await self.mcp_loc_client.call_tool(content)\n",
    "```\n",
    "\n",
    "The MCP client in [`python-server/integration/mcp_client.py`](python-server/integration/mcp_client.py#L50-L60) calls the tool directly to minimize latency - see the `call_tool` function starting at line 50:\n",
    "\n",
    "```python\n",
    "async def call_tool(self, input):\n",
    "    if isinstance(input, str):\n",
    "        input = json.loads(input)\n",
    "    \n",
    "    tool_name = input.get(\"tool\", \"search_places\")\n",
    "    query = input.get(\"query\", input)\n",
    "    \n",
    "    response = await self.session.call_tool(tool_name, {\"query\": query})\n",
    "    result = []\n",
    "    for c in response.content:\n",
    "        result.append(c.text)\n",
    "    return result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab: Test MCP Integration\n",
    "\n",
    "1. Restart the Python WebSocket server to enable MCP integration:\n",
    "   - Press `Ctrl + C` to stop the service\n",
    "   - Run with MCP enabled:\n",
    "     ```bash\n",
    "     python server.py --agent mcp\n",
    "     ```\n",
    "\n",
    "2. Choose **MCP - get location** from the test profile dropdown:\n",
    "\n",
    "   ![Test Profile MCP](static/image-37.png)\n",
    "\n",
    "3. Try questions like:\n",
    "   - \"Find me the location of the largest zoo in Seattle, Washington.\"\n",
    "   - \"Find the largest shopping mall in New York City.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate with Strands Agents\n",
    "\n",
    "[Strands Agents](https://strandsagents.com/0.1.x) is an open source SDK that takes a model-driven approach to building and running AI agents. In this lab, we demonstrate an agentic workflow pattern using Strands Agent to delegate complex reasoning and orchestration to an external integration.\n",
    "\n",
    "### Tool Routing by External Agentic Workflow\n",
    "\n",
    "![Sonic Strands Processing](static/image-38.png)\n",
    "\n",
    "The Strands Agents use two tools:\n",
    "- AWS Location Service MCP server\n",
    "- Weather API wrapped as a Strands Tool\n",
    "\n",
    "The Weather tool requires latitude and longitude, so the agent first gets geo-coordinates from the location service before retrieving weather data. This is handled automatically by Strands Agents.\n",
    "\n",
    "The workflow:\n",
    "1. Users ask: \"What's the weather like in Seattle today?\"\n",
    "2. Nova Sonic uses a generic ToolUse definition and returns the ToolName\n",
    "3. Nova Sonic calls the Strands Agents with the input 'weather in Seattle'\n",
    "4. Strands Agents apply reasoning to determine orchestration, call tools, and generate response\n",
    "5. Nova Sonic processes the Agent response and generates audio output\n",
    "\n",
    "> **Note**: Strands Agents use Nova Lite for reasoning (lower latency). For complex logic, you may opt for a larger model with increased latency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Configuration\n",
    "\n",
    "Located at: [`react-client/src/helper/s2sEvents.js`](react-client/src/helper/s2sEvents.js#L28-L67) - see the `DEFAULT_TOOL_CONFIG` starting at line 28\n",
    "\n",
    "```javascript\n",
    "{\n",
    "  \"toolSpec\": {\n",
    "    \"name\": \"externalAgent\",\n",
    "    \"description\": \"Get weather information for specific locations.\",\n",
    "    \"inputSchema\": {\n",
    "      \"json\": JSON.stringify({\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The search query to find relevant information\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "      })\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle ToolUse Event\n",
    "\n",
    "In [`python-server/s2s_session_manager.py`](python-server/s2s_session_manager.py#L300-L303) - see the Strands Agent integration around line 300:\n",
    "\n",
    "```python\n",
    "# Strands Agent integration - weather questions\n",
    "if toolName == \"externalagent\":\n",
    "    if self.strands_agent:\n",
    "        result = self.strands_agent.query(content)\n",
    "```\n",
    "\n",
    "The Strands Agents implementation in [`python-server/integration/strands_agent.py`](python-server/integration/strands_agent.py#L9-L25) - see the `weather` function starting at line 9 and the `StrandsAgent` class starting at line 27:\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def weather(lat, lon: float) -> str:\n",
    "    \"\"\"Get weather information for a given lat and lon\"\"\"\n",
    "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": str(lat),\n",
    "        \"longitude\": str(lon),\n",
    "        \"current_weather\": True\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()[\"current_weather\"]\n",
    "\n",
    "class StrandsAgent:\n",
    "    def __init__(self):\n",
    "        # Launch AWS Location Service MCP Server\n",
    "        self.aws_location_srv_client = MCPClient(lambda: stdio_client(\n",
    "            StdioServerParameters(\n",
    "                command=\"uvx\", \n",
    "                args=[\"awslabs.aws-location-mcp-server@latest\"],\n",
    "                env=env)\n",
    "            ))\n",
    "        \n",
    "        # Create Strands Agent with Nova Lite\n",
    "        bedrock_model = BedrockModel(\n",
    "            model_id=\"amazon.nova-lite-v1:0\",\n",
    "            boto_session=session\n",
    "        )\n",
    "        tools = self.aws_location_srv_tools\n",
    "        tools.append(weather)\n",
    "        self.agent = Agent(\n",
    "            tools=tools, \n",
    "            model=bedrock_model,\n",
    "            system_prompt=\"You are a chat agent tasked with answering location and weather-related questions.\"\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab: Test Strands Agents Integration\n",
    "\n",
    "1. Restart the Python WebSocket server:\n",
    "   - Press `Ctrl + C` to stop the service\n",
    "   - Run with Strands enabled:\n",
    "     ```bash\n",
    "     python server.py --agent strands\n",
    "     ```\n",
    "\n",
    "2. Choose **Strands Agents - get weather** from the test profile dropdown:\n",
    "\n",
    "   ![Test Profile Strands](static/image-39.png)\n",
    "\n",
    "3. Ask: \"What's the weather like in Seattle today?\"\n",
    "\n",
    "4. In the Python WebSocket terminal, you should see the Strands Agent's \"thinking\" process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "In this lab, you've learned about:\n",
    "\n",
    "✅ **MCP Integration**: Using Model Context Protocol for external tool access with minimal latency\n",
    "✅ **Strands Agents**: Delegating complex reasoning to external agentic workflows\n",
    "✅ **Design Trade-offs**: Understanding when to use different integration patterns based on complexity and latency requirements\n",
    "✅ **Tool Configuration**: Setting up different types of tools for various use cases\n",
    "\n",
    "## Architecture Patterns Summary\n",
    "\n",
    "- **Direct Nova Sonic Tools**: Best for simple, low-latency interactions\n",
    "- **MCP Integration**: Ideal for standardized external tool access\n",
    "- **Strands Agents**: Perfect for complex reasoning and multi-step workflows\n",
    "- **RAG with Knowledge Bases**: Essential for domain-specific information retrieval\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Amazon Nova Sonic Documentation](https://docs.aws.amazon.com/nova/latest/userguide/speech.html)\n",
    "- [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)\n",
    "- [Strands Agents Documentation](https://strandsagents.com/0.1.x)\n",
    "- [Amazon Nova Samples GitHub Repository](https://github.com/aws-samples/amazon-nova-samples)\n",
    "- [AWS Location Service MCP Server](https://github.com/awslabs/mcp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
