{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Core Functionality\n",
    "\n",
    "> **⚠️ Browser Compatibility Notice**: This lab requires **Google Chrome browser** for optimal performance. Please ensure you're using Chrome before proceeding.\n",
    "\n",
    "In this lab, you'll learn about building a real-time voice chat application using Nova Sonic's bidirectional streaming API. You'll understand the event-based architecture, tool use handling, conversation history management, and guardrails implementation.\n",
    "\n",
    "**Prerequisites:** Complete Lab 0 - Introduction to Nova Sonic via AWS Console to understand Nova Sonic's capabilities and behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Event Flow\n",
    "\n",
    "To initiate a conversation with Nova Sonic, a sequence of JSON-formatted events must be sent to the Nova Sonic connection via Bedrock. The diagram below illustrates the event flow between the client (middle server) and the Nova Sonic system.\n",
    "\n",
    "![Nova Sonic Event Flow](static/image-1.png)\n",
    "\n",
    "For more details on Amazon Nova Sonic events, please refer to:\n",
    "- [Input Events](https://docs.aws.amazon.com/nova/latest/userguide/input-events.html)\n",
    "- [Output Events](https://docs.aws.amazon.com/nova/latest/userguide/output-events.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Overview\n",
    "\n",
    "The Nova Sonic Speech-to-Speech model and its APIs have been designed and optimized for real-time, conversational interactions through an open bidirectional audio stream or channel configuration.\n",
    "\n",
    "For architectures that require an internet-exposed connection to serve mobile or web clients, the following approach is recommended:\n",
    "\n",
    "![Nova Sonic Sample Architecture](static/image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Process\n",
    "\n",
    "### Starting the Python WebSocket Server\n",
    "\n",
    "1. Use the terminal command at the bottom of the Code Editor. If it's not open, click the icon in the top-right corner to launch it.\n",
    "\n",
    "   ![Open SageMaker Studio](static/image-3.png)\n",
    "\n",
    "2. Start the Python websocket server:\n",
    "\n",
    "   ```bash\n",
    "   cd python-server\n",
    "   python server.py\n",
    "   ```\n",
    "\n",
    "   ![WebSocket Server Running](static/image-8.png)\n",
    "\n",
    "   The WebSocket server will start on port 8081."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the React Frontend App\n",
    "\n",
    "1. Keep the WebSocket terminal open. Now, open a new terminal to start the React client app. Click the **+** button to open a new terminal.\n",
    "\n",
    "   ![VSCode New Terminal](static/image-9.png)\n",
    "\n",
    "2. Navigate to the REACT client folder, then setup and run the react app:\n",
    "\n",
    "   ```bash\n",
    "   cd react-client\n",
    "   npm ci\n",
    "   npm start\n",
    "   ```\n",
    "\n",
    "   It may take a few minutes to build and run the app for the first time.\n",
    "\n",
    "3. If your browser blocks opening a new tab, go to the **Ports** tab to find the URL and open it manually.\n",
    "\n",
    "   ![VSCode Ports Tab](static/image-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversing with Nova Sonic\n",
    "\n",
    "In this hands-on lab, we will use the frontend React app to engage in an audio conversation with the Amazon Nova Sonic model.\n",
    "\n",
    "![Demo UI](static/image-11.png)\n",
    "\n",
    "1. Start by asking questions like \"Hi Nova, how are you?\" and enjoy chatting with Nova Sonic.\n",
    "\n",
    "2. When using Chrome, ensure the sound setting is set to **Allow**:\n",
    "\n",
    "   ![Chrome Sound Settings](static/image-12.png)\n",
    "\n",
    "3. Grant microphone access when prompted:\n",
    "\n",
    "   ![Microphone Permission](static/image-13.png)\n",
    "\n",
    "4. Click the bubbles to view the raw JSON data sent to and received from Nova Sonic:\n",
    "\n",
    "   ![View JSON Data](static/image-14.png)\n",
    "\n",
    "5. Click the settings icon to customize Voice ID, System Prompt, Tool usage, and Chat history:\n",
    "\n",
    "   ![Demo UI Settings](static/image-15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Output ASR (Automatic Speech Recognition)\n",
    "\n",
    "Each ASR (transcript) returned from Nova Sonic comes in a pair:\n",
    "- **[Speculative]**: Appears before the audioOutput event (what Sonic thinks it will say)\n",
    "- **[Final]**: Follows the audioOutput event (what Sonic actually said)\n",
    "\n",
    "![Sonic ASR](static/image-16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Parameters\n",
    "\n",
    "### VoiceId\n",
    "Specified in the `PromptStart` event - determines which voice Sonic should use.\n",
    "\n",
    "### ToolConfiguration\n",
    "Included in the `PromptStart` event:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"tools\": [\n",
    "    {\n",
    "      \"toolSpec\": {\n",
    "        \"name\": \"getDateTool\",\n",
    "        \"description\": \"get information about the current day\",\n",
    "        \"inputSchema\": {\n",
    "          \"json\": JSON.stringify({\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {},\n",
    "            \"required\": []\n",
    "          })\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### System Prompt\n",
    "Included in the first `textInput` event:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"event\": {\n",
    "    \"textInput\": {\n",
    "      \"promptName\": \"68d4c692-8567-4805-bb36-406e9c8f0f96\",\n",
    "      \"contentName\": \"8e6fe1ae-c3df-4bcd-a0e3-86d3cbf1cc15\",\n",
    "      \"content\": \"You are a friend. The user and you will engage in a spoken dialog exchanging the transcripts of a natural real-time conversation. Keep your responses short, generally two or three sentences for chatty scenarios.\",\n",
    "      \"role\": \"SYSTEM\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt Implementation\n",
    "\n",
    "Now that you've experimented with system prompts in Lab 0, let's understand how they're implemented programmatically. The system prompt is sent as the first `textInput` event with role \"SYSTEM\".\n",
    "\n",
    "### Lab: Implement Custom System Prompts\n",
    "\n",
    "Try modifying the system prompt in the settings panel of the demo UI. The default baseline is:\n",
    "\n",
    "```\n",
    "You are a friend. You and the user will engage in a spoken dialog exchanging the transcripts of a natural real-time conversation. Keep your responses short, generally two or three sentences for chatty scenarios.\n",
    "```\n",
    "\n",
    "Test the different system prompt patterns you learned in Lab 0. For additional best practices, refer to the [official documentation](https://docs.aws.amazon.com/nova/latest/userguide/prompting-speech-best-practices.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Barge-in Handling\n",
    "\n",
    "You've experienced barge-in in Lab 0. Now let's understand how it's implemented in code. Barge-in allows users to interrupt Nova Sonic during speech for more natural conversations.\n",
    "\n",
    "![Sonic Barge In](static/image-17.png)\n",
    "\n",
    "### Test Barge-in Implementation\n",
    "\n",
    "1. Ensure both the Python server and REACT app are running.\n",
    "\n",
    "2. Click \"Start conversation\" and ask: \"I want to travel to Japan during the summer. Can you give me some recommendations?\"\n",
    "\n",
    "3. While Nova Sonic is responding, interrupt by saying: \"I changed my mind. I want to visit Peru instead.\"\n",
    "\n",
    "4. You will see an \"interrupted\" event, and Nova Sonic will respond based on your new command.\n",
    "\n",
    "   ![Sonic Barge In UI](static/image-18.png)\n",
    "\n",
    "Check the REACT code implementation in [`react-client/src/s2s.js`](react-client/src/s2s.js#L209-L232) - specifically the `cancelAudio()` function (line 209) and the interruption detection logic (lines 228-229) that handles barge-in events.\n",
    "\n",
    "![Sonic Barge In Pause Audio](static/image-19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Chat Histories\n",
    "\n",
    "Nova Sonic responses include ASR transcripts for both user and assistant voices. Storing chat history allows resuming sessions when connections close unexpectedly.\n",
    "\n",
    "![Sonic Chat History](static/image-20.png)\n",
    "\n",
    "### Lab: Test Chat History\n",
    "\n",
    "1. Start a conversation and ask: \"Hi Nova, can we resume the reservation?\"\n",
    "\n",
    "   ![Sonic Chat History UI](static/image-21.png)\n",
    "\n",
    "2. Default chat history example:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"content\": \"hi there i would like to cancel my hotel reservation\",\n",
    "    \"role\": \"USER\"\n",
    "  },\n",
    "  {\n",
    "    \"content\": \"Hello! I'd be happy to assist you with cancelling your hotel reservation. To get started, could you please provide me with your full name and the check-in date for your reservation?\",\n",
    "    \"role\": \"ASSISTANT\"\n",
    "  },\n",
    "  {\n",
    "    \"content\": \"yeah so my name is don smith\",\n",
    "    \"role\": \"USER\"\n",
    "  },\n",
    "  {\n",
    "    \"content\": \"Thank you, Don. Now, could you please provide me with the check-in date for your reservation?\",\n",
    "    \"role\": \"ASSISTANT\"\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling ToolUse\n",
    "\n",
    "Tool Use (function calls) enable external functionality in Amazon Nova, such as API calls or code functions.\n",
    "\n",
    "### Setup toolConfiguration\n",
    "\n",
    "When starting a new session with Nova Sonic, provide the Tool configuration in the `PromptStart` event:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"tools\": [\n",
    "    {\n",
    "      \"toolSpec\": {\n",
    "        \"name\": \"getDateTool\",\n",
    "        \"description\": \"get information about the current day\",\n",
    "        \"inputSchema\": {\n",
    "          \"json\": JSON.stringify({\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {},\n",
    "            \"required\": []\n",
    "          })\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Receive and Process the ToolUse Event\n",
    "\n",
    "Throughout the conversation, Sonic will trigger a ToolUse event if the user input matches one of the tool specs.\n",
    "\n",
    "![Sonic ToolUse Events](static/image-22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test ToolUse Using the Sample App\n",
    "\n",
    "1. Ensure both the Python server and REACT app are running.\n",
    "\n",
    "2. Click \"Start conversation\" and ask: \"What time is it?\" or \"I'm in the Eastern Time Zone—what time is it currently?\"\n",
    "\n",
    "3. Nova Sonic will respond with the correct date. You should see ToolUse and ToolResult events on the UI.\n",
    "\n",
    "   ![Sonic ToolUse UI](static/image-23.png)\n",
    "\n",
    "4. Click the red ToolUse event to view details:\n",
    "\n",
    "   ![Sonic ToolUse Event](static/image-24.png)\n",
    "\n",
    "5. Click the red ToolResult event to view details:\n",
    "\n",
    "   ![Sonic ToolResult Event](static/image-25.png)\n",
    "\n",
    "6. Check the Python code implementation in [`python-server/s2s_session_manager.py`](python-server/s2s_session_manager.py#L268-L330) - specifically the `processToolUse` function starting at line 268 to see how different tool types are handled and processed.\n",
    "\n",
    "   ![Sonic ToolUse Processing](static/image-26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Guardrails\n",
    "\n",
    "Three key aspects to consider when applying guardrails to Nova Sonic:\n",
    "\n",
    "1. **Built-in RAI**: Nova offers integrated Responsible AI (RAI) that aligns with the AWS Acceptable Use Policy. See [Nova RAI documentation](https://docs.aws.amazon.com/nova/latest/userguide/responsible-use.html).\n",
    "\n",
    "2. **System Prompts**: Incorporate additional policy evaluation logic as part of the system prompts.\n",
    "\n",
    "3. **Moderate ToolResult input**: When invoking external function calls via ToolUse, validate the returned context using the [ApplyGuardrail API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ApplyGuardrail.html).\n",
    "\n",
    "### Lab: Test Guardrails with System Prompts\n",
    "\n",
    "Update the system prompts with this real estate agent sample, then ask: \"Can you tell me if the seller is male or female?\"\n",
    "\n",
    "```\n",
    "You are a real estate agent assisting customers by providing accurate, factual information about real estate properties. \n",
    "Your responses should be clear, informative, and strictly professional. Do not include or imply any references to ethnicity, gender, or other protected attributes, in accordance with fair housing regulations. \n",
    "Focus solely on property features, location details, market trends, and other objective criteria.\n",
    "```\n",
    "\n",
    "Nova Sonic will gracefully refuse to share information that goes against the system prompt instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "In this lab, you've learned about:\n",
    "\n",
    "✅ **Event-based architecture**: How Nova Sonic processes input and output events\n",
    "✅ **System prompt implementation**: Programmatic control of assistant behavior\n",
    "✅ **Barge-in handling**: Natural interruption processing in code\n",
    "✅ **Chat history management**: Maintaining conversation context\n",
    "✅ **Tool use integration**: External function calling capabilities\n",
    "✅ **Guardrails implementation**: Responsible AI practices\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Amazon Nova Sonic Documentation](https://docs.aws.amazon.com/nova/latest/userguide/speech.html)\n",
    "- [Input Events Reference](https://docs.aws.amazon.com/nova/latest/userguide/input-events.html)\n",
    "- [Output Events Reference](https://docs.aws.amazon.com/nova/latest/userguide/output-events.html)\n",
    "- [Nova Sonic Best Practices](https://docs.aws.amazon.com/nova/latest/userguide/prompting-speech-best-practices.html)\n",
    "- [Amazon Nova Samples GitHub Repository](https://github.com/aws-samples/amazon-nova-samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Add a Coin Flip Tool\n",
    "\n",
    "Now that you understand how tools work, it's your turn to implement a simple coin flip tool to help with decision-making.\n",
    "\n",
    "### Your Task\n",
    "\n",
    "Create a new tool called `coinFlipTool` that randomly returns either \"heads\" or \"tails\" when called.\n",
    "\n",
    "### Hints\n",
    "\n",
    "1. **Tool Specification**: Follow the same pattern as `getDateTool` - this tool doesn't need any input parameters\n",
    "2. **Tool Name**: Use `coinFlipTool` as the name\n",
    "3. **Description**: Write a clear description so Nova Sonic knows when to use it (think about decision-making scenarios)\n",
    "4. **Processing Logic**: Look at how `getDateTool` is handled in `s2s_session_manager.py` and add a similar `if` block for your coin flip tool\n",
    "5. **Randomness**: Python's `random` module can help you generate random results\n",
    "\n",
    "### Test Your Implementation\n",
    "\n",
    "Try asking Nova Sonic:\n",
    "- \"Flip a coin for me\"\n",
    "- \"Should I go to the gym today? Flip a coin\"\n",
    "- \"Help me decide - heads or tails?\"\n",
    "- \"I can't decide between pizza or sushi. Flip a coin\"\n",
    "\n",
    "### Expected Result\n",
    "\n",
    "When working correctly:\n",
    "1. Nova Sonic recognizes your coin flip request\n",
    "2. A ToolUse event appears in the UI for \"coinFlipTool\"\n",
    "3. The tool returns either \"heads\" or \"tails\" randomly\n",
    "4. Nova Sonic speaks the result naturally in conversation\n",
    "5. Each time you ask, you might get a different result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
